---
title: "MA0501 – Tarea 7"
author: 
  - name: "Diego Alberto Vega Víquez - C38367" 
    email: "diegovv13@gmail.com"
  - name: "José Carlos Quintero Cedeño - C26152" 
    email: "jose.quinterocedeno@ucr.ac.cr"
  - name: "Gabriel Valverde Guzmán - C38060"
    email: "GABRIEL.VALVERDEGUZMAN@ucr.ac.cr"
date: today
lang: es
format:
  pdf:
    documentclass: article
    fontsize: 11pt
    linestretch: 1.3
    geometry:
      - top=2.5cm
      - bottom=2.5cm
      - left=2.5cm
      - right=2.5cm
      - headheight=15pt
      - footskip=1.25cm
    toc: true
    toc-depth: 1
    number-sections: false
    classoption:
      - oneside
      - titlepage 
    openany: true
    colorlinks: false   
    top-level-division: section
    include-in-header: 
      text: |
        \usepackage[most]{tcolorbox}
        \usepackage[hidelinks]{hyperref}
        \usepackage{setspace}
        \AtBeginDocument{\setstretch{1.0}} % ← interlineado
  html:
    code-annotations: hover
    toc: true
    toc-depth: 1
    toc-location: left
    toc_float: yes
    html-math-method: katex
    css: styles.css
    df_print: paged
    theme: flatly
    highlight: tango
    embed-resources: true
    page-layout: full
editor: 
  markdown: 
    wrap: 72
---

\newpage

# Ejercicio 1

::: {.callout-note title="Instrucción del ejercicio 1"}

Programe en **R** los algoritmos de **Punto Fijo** y del **método de Newton–Raphson** para sistemas de ecuaciones no lineales de $n$ variables vistos en clase.

:::

**Solución**

**Punto fijo**
```{r}
#| code-fold: true

punto.fijo.vv <- function(p0, F, tol = 1e-8, N = 100){
  x.prev <- as.numeric(p0)
  m <- length(p0)
  x.next <- x.prev
  for (i in 1:N) {
    for (j in 1:m) {
      x.next[j] <- F[[j]](x.prev)
    }
    if(abs(max(x.next - x.prev)) < tol){
      return(x.next)
    }
    x.prev <- x.next
  }
  return(paste0("Numero maximo de iteraciones excedido: ", N))
}

#Prueba
f1 <- function(x) (1/3)*cos(x[2]*x[3]) + 1/6
f2 <- function(x) (1/9)*sqrt(x[1]^2 + sin(x[3]) + 1.06) - 0.1
f3 <- function(x) -(1/20)*exp(-x[1]*x[2]) - (10*pi - 3)/60

F <- list(f1, f2, f3)

p0 <- c(0, 0, 0)
sol <- punto.fijo.vv(p0, F)
sol
```
**Newton Raphson**
```{r}
#| code-fold: true

#funciones auxiliares
evaluar.componente <- function(gj, x){
  return(gj(x))
}

evaluar.funcion.vectorial <- function(G, x){
  vapply(G, evaluar.componente, numeric(1), x = x)
}

calcular.jacobiano <- function(G, x, h = sqrt(.Machine$double.eps)){
  x <- as.numeric(x)
  m <- length(x)
  J <- matrix(0, nrow = m, ncol = m)
  for (j in 1:m) {
    ej <- rep(0, m)
    ej[j] <- 1
    fp <- evaluar.funcion.vectorial(G, x + h * ej)
    fm <- evaluar.funcion.vectorial(G, x - h * ej)
    J[, j] <- (fp - fm)/(2*h)
  }
  return(J)
}

#funcion
newton.raphson.vv <- function(p0, F, tol = 1e-8, N = 50){
  x.prev <- as.numeric(p0)
  for (i in 1:N) {
    J <- calcular.jacobiano(F, x.prev)
    Fx <- evaluar.funcion.vectorial(F, x.prev)
    delta <- try(solve(J, Fx), silent = TRUE)
    if(inherits(delta, "try-error") || any(!is.finite(delta))) {
      stop("Falla al resolver el sistema lineal: jacobiana singular o mal condicionada")
    }
    x.next <- x.prev - as.numeric(delta)
    
    if(abs(max(x.next - x.prev)) < tol){
      return(x.next)
    }
    x.prev <- x.next
  }
  return("Numero maximo de iteraciones excedido")
}

#prueba
r1 <- function(x) x[1]^2 + x[2]^2 + 0.6*x[2] - 0.16
r2 <- function(x) x[1]^2 - x[2]^2 + x[1] -1.6*x[2] - 0.14

R <- list(r1, r2)
p0 <- c(0.6, 0.25)

sol <- newton.raphson.vv(p0, R)
sol
```

# Ejercicio 2

::: {.callout-note title="Instrucción del ejercicio 2"}

El **Método Simplificado de Newton** o de **Newton–Kantorovich** tiene el siguiente esquema de iteración:

$$
x_{n+1} = x_n - [df(x_0)]^{-1} f(x_n), \qquad n = 0, 1, 2, \dots
$$

donde $df(x)$ es la matriz Jacobiana de $f$.

a) Escriba una función en **R** para este método.

b) Sea $C \subset \mathbb{R}^n$ un abierto y sea $f : \Omega \to \mathbb{R}^n$ una aplicación diferenciable, sea $C \subset \Omega$ convexo y cerrado y sea $x_0$ en el interior de $C$.  
Se supone que $df$ verifica la **condición de Lipschitz** dentro de $C$ con parámetro $\lambda > 0$ y que $df(x_0)$ es invertible. Se denota:

$$
A_0 = [df(x_0)]^{-1}, 
\quad 
\alpha = \|A_0\|, 
\quad 
\beta = \|A_0 f(x_0)\|,
\quad 
\gamma = \alpha \beta \lambda.
$$

Se supone además que $\beta \ne 0$ y que $\gamma < \tfrac{1}{4}$.  
Se denota por $t_0 < 1$ las raíces de la ecuación $\gamma t^2 - t + 1 = 0$  
y se supone que la bola cerrada $B_0$ de centro $x_0$ y radio $\beta t_0$ está contenida en $C$.

Finalmente, denotamos por $g$ la aplicación definida en $\Omega$ por:

$$
g(x) := x - A_0 f(x).
$$

1. Muestre que $\forall x, y \in C$:

   $$
   \|f(x) - f(y) - df(y)(x - y)\| \le \frac{\lambda}{2} \|x - y\|^2.
   $$

   [Sugerencia: Considere $\varphi : [0,1] \to \mathbb{R}^n$ definida por $\varphi(t) := f(y + t(x - y))$ y use el hecho de que $df$ verifica la condición de Lipschitz.]

2. Muestre que $g(B_0) \subset B_0$.  
   [Sugerencia: Use el inciso anterior y la definición de $t_0$.]

3. Muestre que $\forall x, y \in B_0$:

   $$
   \|g(x) - g(y)\| \le \frac{1 - \sqrt{1 - 4\gamma}}{2} \|x - y\|.
   $$

   [Sugerencia: Pruebe que $\|dg(x)\| \le t_0 = \tfrac{1 - \sqrt{1 - 4\gamma}}{2}$.]

4. Muestre que la sucesión $(x_k)$ definida en $B_0$ por:

   $$
   x_{k+1} := x_k - A_0 f(x_k), \qquad k = 0, 1, 2, \dots
   $$

   converge a $x$, la **solución única** de la ecuación $f(x) = 0$ con $x \in B_0$.

5. Muestre que se tiene la siguiente **cota para el error absoluto**:

   $$
   \|x_k - x\| \le \frac{\beta t_0}{1 - \delta} \, \delta^k, 
   \qquad k = 0, 1, 2, \dots
   $$

   donde:
   $$
   \delta := \frac{1 - \sqrt{1 - 4\gamma}}{2}.
   $$

:::

**Solución**

a) La diferencia entre este metodo y el de Newton-Raphson es que el jacobiano se toma como constante (a partir del punto de partida que se tome), de modo que la funcion quedaria de la siguiente manera:

```{r}
#| code-fold: true

newton.kantorovich.vv <- function(p0, F, tol = 1e-8, N = 50){
  x.prev <- as.numeric(p0)
  J <- calcular.jacobiano(F, p0)
  for (i in 1:N) {
    Fx <- evaluar.funcion.vectorial(F, x.prev)
    delta <- try(solve(J, Fx), silent = TRUE)
    if(inherits(delta, "try-error") || any(!is.finite(delta))) {
      stop("Falla al resolver el sistema lineal: jacobiana singular o mal condicionada")
    }
    x.next <- x.prev - as.numeric(delta)
    
    if(abs(max(x.next - x.prev)) < tol){
      return(x.next)
    }
    x.prev <- x.next
  }
  return("Numero maximo de iteraciones excedido")
}

#prueba
r1 <- function(x) x[1]^2 + x[2]^2 + 0.6*x[2] - 0.16
r2 <- function(x) x[1]^2 - x[2]^2 + x[1] -1.6*x[2] - 0.14

R <- list(r1, r2)
p0 <- c(0.6, 0.25)

sol <- newton.kantorovich.vv(p0, R)
sol
```

b)

  1. Defina $\varphi:[0,1]\to\mathbb{R}^n$ por $\varphi(t)=f\big(y+t(x-y)\big)$. Entonces
$\varphi'(t)=df\big(y+t(x-y)\big)(x-y)$ y, por el teorema fundamental del cálculo,

$$
f(x)-f(y)=\int_0^1 df\big(y+t(x-y)\big)(x-y)\,dt.
$$
    Restando $df(y)(x-y)$ y usando Lipschitz para $df$,

\begin{align*}
\lVert f(x)-f(y)-df(y)(x-y)\rVert
&=\left\lVert\int_0^1 \big(df(y+t(x-y))-df(y)\big)(x-y)\,dt\right\rVert \\
&\le \int_0^1 \lambda t \lVert x-y\rVert^2\,dt
= \frac{\lambda}{2}\lVert x-y\rVert^2.
\end{align*}
    $\blacksquare$

  2. Sea $x\in B_0$ y ponga $\Delta=x-x_0$. Por el punto anterior con $y=x_0$,
  $$
  f(x)-f(x_0)-df(x_0)\Delta=:r(x), \qquad \lVert r(x)\rVert\le \frac{\lambda}{2}\lVert\Delta\rVert^2.
  $$
    Entonces
  
  \begin{align*}
  g(x)-x_0
  &= (x-x_0)-A_0\big(f(x)-f(x_0)\big)-A_0f(x_0) \\
  &= \underbrace{\big(I-A_0df(x_0)\big)}_{=\,0}\Delta - A_0 r(x) - A_0 f(x_0),
  \end{align*}
  
    de donde
  $$
  \lVert g(x)-x_0\rVert \le \alpha\,\frac{\lambda}{2}\lVert\Delta\rVert^2 + \beta
  \le \alpha\,\frac{\lambda}{2}(\beta t_0)^2 + \beta
  = \beta\!\left(1+\frac{\gamma}{2}t_0^2\right).
  $$
    Como $t_0$ satisface $\gamma t_0^2-t_0+1=0$, se tiene $t_0=1+\gamma t_0^2$, y por tanto
  $1+\frac{\gamma}{2}t_0^2\le t_0$. Luego
  $$
  \lVert g(x)-x_0\rVert \le \beta t_0,
  $$
    es decir, $g(x)\in B_0$. Por arbitrariedad de $x$, $g(B_0)\subset B_0$. 

    $\blacksquare$

  3. $g$ es una contracción en $B_0$

    Note que $dg(x)=I-A_0df(x)$. Para $x\in B_0$,
$$
\lVert dg(x)\rVert \le \lVert A_0\rVert \,\lVert df(x)-df(x_0)\rVert
\le \alpha\lambda \lVert x-x_0\rVert
\le \alpha\lambda\,\beta t_0=\gamma t_0.
$$
    Con $t_0=\dfrac{1-\sqrt{1-4\gamma}}{2\gamma}$ se obtiene
$$
\sup_{x\in B_0}\lVert dg(x)\rVert \le \gamma t_0
= \frac{1-\sqrt{1-4\gamma}}{2} =: \delta \in (0,1).
$$
    Por el teorema del valor medio en espacios de Banach,
$$
\lVert g(x)-g(y)\rVert \le \delta\,\lVert x-y\rVert
\qquad \forall\,x,y\in B_0,
$$
    que es la cota solicitada:
$$
\lVert g(x)-g(y)\rVert \le \frac{1-\sqrt{1-4\gamma}}{2}\,\lVert x-y\rVert.
$$
    $\blacksquare$

  4. Existencia y unicidad de solución en $B_0$ y convergencia de $x_{k+1}=g(x_k)$

    De (2.) y (3.), $g:B_0\to B_0$ es una contracción con constante $\delta\in(0,1)$. 

    Por el **teorema del punto fijo de Banach**, existe un único $x\in B_0$ tal que $g(x)=x$. 

    Como $A_0$ es invertible, $g(x)=x$ implica $A_0 f(x)=0$, luego $f(x)=0$.

    Si definimos $x_{k+1}=g(x_k)$ con $x_0\in B_0$, entonces $(x_k)$ converge a dicho punto fijo $x$, que es la solución única de $f(x)=0$ en $B_0$. 
    
    $\blacksquare$

  5. Cota para el error absoluto

    Para una contracción con constante $\delta$, vale (estimación a posteriori de Banach)
$$
\lVert x_k-x\rVert \le \frac{\delta^k}{1-\delta}\,\lVert x_1-x_0\rVert
\qquad (k=0,1,2,\dots).
$$
    Aquí $x_1-x_0=g(x_0)-x_0=-A_0 f(x_0)$, por lo que $\lVert x_1-x_0\rVert=\beta$. Además, como $t_0\ge 1$, tenemos $\beta\le \beta t_0$, y por lo tanto
$$
\boxed{\;\lVert x_k-x\rVert \le \frac{\beta t_0}{1-\delta}\,\delta^k,\qquad
\delta=\frac{1-\sqrt{1-4\gamma}}{2}\;}
$$
    que es exactamente la cota pedida. 
    
    $\blacksquare$





# Ejercicio 3

::: {.callout-note title="Instrucción del ejercicio 3"}

Resuelva el siguiente sistema de ecuaciones usando el **método de punto fijo** (pruebe antes que se cumplen las hipótesis del teorema):

$$
\begin{cases}
F_1(x, y) = 2x^2 - xy - 5x + 1 = 0, \\
F_2(x, y) = x + 3\log_{10}x - y^2 = 0.
\end{cases}
$$

:::

**Solución**

Verificación de la hipótesis de convergencia para el método de punto fijo

Sea el sistema de ecuaciones dado por:

$$
\begin{cases}
F_1(x,y) = 2x^2 - xy - 5x + 1 = 0, \\[4pt]
F_2(x,y) = x + 3\log_{10}x - y^2 = 0,
\end{cases}
$$

que puede escribirse en forma de punto fijo mediante las funciones:

$$
\begin{cases}
f_1(x,y) = \sqrt{\dfrac{xy + 5x - 1}{2}}, \\[8pt]
f_2(x,y) = \sqrt{x + 3\log_{10}(x)}.
\end{cases}
$$

De este modo, el mapeo de punto fijo es **G(x,y) = (f₁(x,y), f₂(x,y))**, y su jacobiano viene dado por:

$$
J_G(x,y) =
\begin{pmatrix}
\dfrac{\partial f_1}{\partial x} & \dfrac{\partial f_1}{\partial y} \\[8pt]
\dfrac{\partial f_2}{\partial x} & \dfrac{\partial f_2}{\partial y}
\end{pmatrix}
=
\begin{pmatrix}
\dfrac{y + 5}{4 f_1} & \dfrac{x}{4 f_1} \\[8pt]
\dfrac{1 + \dfrac{3}{x\ln 10}}{2\sqrt{x + 3\log_{10}x}} & 0
\end{pmatrix}.
$$



Región de análisis

Consideremos un rectángulo **D = [3.2, 3.8] × [2.0, 2.6]** que contiene la solución positiva aproximada **(x, y) ≈ (3.487, 2.262)**.

En este dominio, el valor mínimo de f₁ ocurre en (x, y) = (3.2, 2.0):

$$
f_{1,\min} = \sqrt{\dfrac{3.2 \cdot 2.0 + 5 \cdot 3.2 - 1}{2}} = \sqrt{10.7} \approx 3.272.
$$



Cotas de las derivadas parciales

$$
\begin{aligned}
\left|\frac{\partial f_1}{\partial x}\right| &\le \frac{2.6 + 5}{4 \cdot 3.272} = 0.581, \\[4pt]
\left|\frac{\partial f_1}{\partial y}\right| &\le \frac{3.8}{4 \cdot 3.272} = 0.291.
\end{aligned}
$$

Para **∂f₂/∂x**, el máximo ocurre en x = 3.2:

$$
\begin{aligned}
v &= 3.2 + 3\log_{10}(3.2) \approx 4.715, \quad \sqrt{v} \approx 2.172, \\[4pt]
1 + \frac{3}{x \ln 10} &\le 1 + \frac{3}{3.2 \cdot 2.3026} \approx 1.407, \\[4pt]
\Rightarrow \left|\frac{\partial f_2}{\partial x}\right| &\le \frac{1.407}{2 \cdot 2.172} \approx 0.324.
\end{aligned}
$$



Criterio de contracción (Observación 1)

Usando la norma 1 (suma máxima por columnas):

$$
\begin{aligned}
\text{Columna 1: } &\left|\frac{\partial f_1}{\partial x}\right| + \left|\frac{\partial f_2}{\partial x}\right| \le 0.581 + 0.324 = 0.905 < 1, \\[4pt]
\text{Columna 2: } &\left|\frac{\partial f_1}{\partial y}\right| \le 0.291 < 1.
\end{aligned}
$$

También se cumple con la norma infinito (suma máxima por filas):

$$
\begin{aligned}
\text{Fila 1: } &0.581 + 0.291 = 0.872 < 1, \\[4pt]
\text{Fila 2: } &0.324 < 1.
\end{aligned}
$$



Conclusión

En el dominio D se cumple que:

$$
\sup_{(x,y)\in D} \|J_G(x,y)\|_1 < 1 \quad \text{y} \quad \sup_{(x,y)\in D} \|J_G(x,y)\|_\infty < 1.
$$

Por tanto, según la **Observación 1**, el mapeo G(x,y) es una contracción en D, lo cual garantiza que el **método de punto fijo converge localmente** hacia la solución positiva del sistema.


```{r}
#| code-fold: true

f1 <- function(x) sqrt((x[1]*x[2] + 5*x[1] - 1)/(2))
f2 <- function(x) sqrt(x[1] + 3*log10(x[1]))

F <- list(f1, f2)
punto.fijo.vv(c(1,1), F)
```



# Ejercicio 4

::: {.callout-note title="Instrucción del ejercicio 4"}

El sistema no lineal:

$$
\begin{cases}
x_1(1 - x_1) + 4x_2 = 12, \\
(x_1 - 2)^2 + (2x_2 - 3)^2 = 25,
\end{cases}
$$

tiene dos soluciones.

**a)** Aproxime estas dos soluciones gráficamente.

**b)** Use las aproximaciones encontradas en (a) para encontrar las soluciones usando el **método de Newton** y el **método de Newton–Kantorovich**.

:::

**Solución**

a)

si se grafican ambas ecuaciones en un programa como GeoGebra, se obtiene que las dos posibles soluciones estan en $(-1, 3)$ y $(2.5, 4)$

b)

```{r}
#| code-fold: true

f1 <- function(x) x[1]*(1-x[1]) + 4*x[2] - 12
f2 <- function(x) (x[1] - 2)^2 + (2*x[2] - 3)^2 - 25
F <- list(f1, f2)
newton.raphson.vv(c(-1, 3), F)
newton.raphson.vv(c(2.5, 4), F)
newton.kantorovich.vv(c(-1,3), F)
newton.kantorovich.vv(c(2.5, 4), F)
```


# Ejercicio 5

::: {.callout-note title="Instrucción del ejercicio 5"}

Usando el **método de Newton** y el **método de Newton–Kantorovich**, resuelva el sistema:

$$
\begin{cases}
15x_1 + x_2^2 - 4x_3 = 13, \\
x_1^2 + 10x_2 - x_3 = 11, \\
x_2^3 - 25x_3 = -22,
\end{cases}
$$

en 

$$
D := \{(x_1, x_2, x_3)^t \in \mathbb{R}^3 \text{ tal que } 0 \le x_i \le 2 \text{ para } i = 1, 2, 3\}.
$$

:::

**Solución**

```{r}
#| code-fold: true

f1 <- function(x) 15*x[1] + x[2]^2 - 4*x[3] - 13
f2 <- function(x) x[1]^2 + 10*x[2] - x[3] - 11
f3 <- function(x) x[2]^3 -25*x[3] + 22
F <- list(f1, f2, f3)

newton.raphson.vv(c(0, 0, 0), F)
newton.kantorovich.vv(c(0, 0, 0), F)
```

