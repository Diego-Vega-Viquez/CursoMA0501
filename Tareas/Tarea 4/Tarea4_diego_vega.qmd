---
title: "MA0501 – Tarea 4"
author: 
  - name: "Diego Alberto Vega Víquez - C38367" 
    email: "diegovv13@gmail.com"
  - name: "José Carlos Quintero Cedeño - C26152" 
    email: "jose.quinterocedeno@ucr.ac.cr"
  - name: "Gabriel Valverde Guzmán - C38060"
    email: "GABRIEL.VALVERDEGUZMAN@ucr.ac.cr"
date: today
lang: es
format:
  pdf:
    documentclass: article
    fontsize: 11pt
    linestretch: 1.3
    geometry:
      - top=2.5cm
      - bottom=2.5cm
      - left=2.5cm
      - right=2.5cm
      - headheight=15pt
      - footskip=1.25cm
    toc: true
    toc-depth: 1
    number-sections: false
    classoption:
      - oneside
      - titlepage 
    openany: true
    colorlinks: false   
    top-level-division: section
    include-in-header: 
      text: |
        \usepackage[most]{tcolorbox}
        \usepackage[hidelinks]{hyperref}
        \usepackage{setspace}
        \AtBeginDocument{\setstretch{1.0}} % ← interlineado
  html:
    code-annotations: hover
    toc: true
    toc-depth: 1
    toc-location: left
    toc_float: yes
    html-math-method: katex
    css: styles.css
    df_print: paged
    theme: flatly
    highlight: tango
    embed-resources: true
---

\newpage

# Ejercicio 1

::: {.callout-note title="Instrucción del ejercicio 1"}

Complete las demostraciones que quedaron pendientes en la clase.

:::

**Solución**


::: {.callout-note title="Teorema 1 [Weierstrass]"}

Sea $f$ continua en $[a, b]$; entonces dado $\varepsilon > 0$, existe $n \in \mathbb{N}$ y $P_n(x) \in P_n$ tal que

$$
\left| f(x) - P_n(x) \right| < \varepsilon, \quad \forall x \in [a, b].
$$


![Polinomio de Bernstein](Imagenes/Polinomio de Bernstein.png){width=400px fig-align="center"}

::: {.callout-caution collapse="true" title="Prueba"}


Sin pérdida de generalidad, suponga que $a = 0$ y $b = 1$. Sea:


$$
B_n(x) = \sum_{k=0}^n \binom{n}{k} x^k (1 - x)^{n-k} f\left( \frac{k}{n} \right),
$$

se puede probar que $B_n(x) \to f(x)$ uniformemente en $[0,1]$:

Vea que 

$$|B_n(x)-f(x)| \le \sum_{k=0}^n \binom{n}{k} x^k (1 - x)^{n-k} \Big|f\left( \frac{k}{n} \right) - f(x)\Big|$$
Note que se tiene una esperanza con respecto a una distribución binomial $\operatorname{Bin}(n,x)$

$$X_n\sim\operatorname{Bin}(n,x) \implies \mathbb{E}\left[f\left(\frac{X_n}{n}\right)\right] = B_n(x)$$

Entonces:

$$
\lvert B_n(x) - f(x) \rvert = \left\lvert \mathbb{E}\left[f\!\left(\tfrac{X_n}{n}\right)\right] - f(x) \right\rvert
$$
Dado que $f$ es continua en $[0,1]$, por el Teorema de Heine–Cantor, también es uniformemente continua.  
Entonces, para todo $\varepsilon > 0$, existe $\delta > 0$ tal que:

$$
|x-y| < \delta \;\;\Rightarrow\;\; |f(x) - f(y)| < \varepsilon
$$
Considere dividir el dominio del índice $k$ en dos regiones:

- Cuando $\left|\tfrac{k}{n} - x\right| < \delta$  
- Cuando $\left|\tfrac{k}{n} - x\right| \geq \delta$

Entonces:

$$
\lvert B_n(x) - f(x) \rvert
\le
\varepsilon \cdot P\!\left(\left|\tfrac{X_n}{n} - x\right| < \delta\right)
+ 2\lVert f\rVert_\infty \cdot P\!\left(\left|\tfrac{X_n}{n} - x\right| \ge \delta\right)
$$

Usando la *desigualdad de Chebyshev* aplicada a $\tfrac{X_n}{n}$, cuya varianza es $\tfrac{x(1-x)}{n}$, el segundo término tiende a $0$ uniformemente en $x\in[0,1]$.


Como el error puede hacerse arbitrariamente pequeño uniformemente en $x$, se concluye:

$$
\sup_{x\in[0,1]} \lvert B_n(x) - f(x) \rvert \;\longrightarrow\; 0
\qquad \text{cuando } n \to \infty.
$$

$\blacksquare$
:::
:::

::: {.callout-note title="Teorema 3"}

Sea $f \in C[a,b]$ y $f \in C^n]a,b[$, si $f$ se anula en $n+1$ puntos distintos,  
$x_0, x_1, \ldots, x_n$ en $[a,b]$. Entonces $\exists \, c \in ]a,b[$ tal que $f^{(n)}(c) = 0$.


::: {.callout-caution collapse="true" title="Prueba"}

**Por inducción sobre $n$**

**Caso base: $n = 1$.**

Si $f(x_0) = f(x_1) = 0$ con $x_0 < x_1$, entonces por el Teorema de Rolle clásico, existe $c \in (x_0, x_1)$ tal que:

$$
f'(c) = 0.
$$

**Hipótesis de inducción:**

Supongamos que el resultado es cierto para $n = k$, es decir, si $f \in C^{k}]a,b[$ y se anula en $k+1$ puntos distintos en $[a,b]$, entonces existe $c \in (a,b)$ tal que $f^{(k)}(c) = 0$.

**Paso inductivo:**

Sea ahora $f \in C^{k+1}]a,b[$ y supongamos que $f(x_0) = f(x_1) = \dots = f(x_{k+1}) = 0$, con $x_0 < x_1 < \dots < x_{k+1}$.

Por el Teorema de Rolle, para cada par consecutivo $(x_i, x_{i+1})$, existe $c_i \in (x_i, x_{i+1})$ tal que:

$$
f'(c_i) = 0.
$$

Eso da una nueva colección de $k+1$ puntos $c_0 < c_1 < \dots < c_k$ donde $f'$ se anula. Entonces, por la hipótesis de inducción aplicada a $f'$, existe un punto $c \in (a,b)$ tal que:

$$
f^{(k+1)}(c) = 0.
$$
$\blacksquare$

:::
:::

::: {.callout-note title="Teorema 6"}

Si $P_n(x)$ es el polinomio de Lagrange que coincide con $f(x)$ en  
$x_0, x_1, \ldots, x_n$, entonces:

\begin{align*}
P_n(x) &= f[x_0] + f[x_0,x_1](x-x_0) + f[x_0,x_1,x_2](x-x_0)(x-x_1) \\
&\quad + \cdots + f[x_0,x_1,\ldots,x_n](x-x_0)(x-x_1)\cdots(x-x_{n-1}) \\
&= f[x_0] + \sum_{k=1}^n f[x_0,\ldots,x_k](x-x_0)\cdots(x-x_{k-1}).
\end{align*}

::: {.callout-caution collapse="true" title="Prueba"}

Si $P_n(x)$ se escribe de la forma

\begin{align*}
P_n(x) &= a_0 + a_1(x-x_0) + a_2(x-x_0)(x-x_1) + \cdots \\
&\quad + a_n(x-x_0)(x-x_1)\cdots(x-x_{n-1}),
\end{align*}

entonces $P_n(x_0) = a_0$. Como $P_n(x_0)=f(x_0)$ se sigue que  
$a_0 = f(x_0) = f[x_0]$.

Además:

\begin{align*}
P_n(x_1) &= a_0 + a_1(x_1-x_0), \\
f(x_1) &= f[x_0] + a_1(x_1-x_0) \quad \Rightarrow \quad a_1 = \frac{f[x_1]-f[x_0]}{x_1-x_0} = f[x_0,x_1].
\end{align*}

Luego, por inducción se puede probar fácilmente que  $a_k = f[x_0, x_1, \ldots, x_k]$.


**Paso base:**

Para $k = 0$, se tiene:

$$
P_n(x_0) = a_0 = f(x_0),
$$

por lo tanto:

$$
a_0 = f[x_0].
$$

**Hipótesis de inducción:**

Supongamos que para algún $k \geq 1$ se cumple que:

$$
a_j = f[x_0, x_1, \dots, x_j] \quad \text{para todo } j = 0, 1, \dots, k-1.
$$

**Paso inductivo:**

Queremos probar que:

$$
a_k = f[x_0, x_1, \dots, x_k].
$$

Evaluamos el polinomio $P_n(x)$ en $x = x_k$. Por construcción, se cumple:

\begin{align*}
P_n(x_k) &= a_0 + a_1(x_k - x_0) + a_2(x_k - x_0)(x_k - x_1) + \cdots \\
&\quad + a_k(x_k - x_0)(x_k - x_1)\cdots(x_k - x_{k-1}).
\end{align*}

Pero también sabemos que $P_n(x_k) = f(x_k)$, y por la hipótesis de inducción:

\begin{align*}
f(x_k) &= f[x_0] + f[x_0, x_1](x_k - x_0) + \cdots \\
&\quad + f[x_0, \dots, x_{k-1}](x_k - x_0)\cdots(x_k - x_{k-2}) \\
&\quad + a_k(x_k - x_0)\cdots(x_k - x_{k-1}).
\end{align*}

Entonces, restando ambos lados, obtenemos:

$$
a_k = \frac{f(x_k) - P_{k-1}(x_k)}{(x_k - x_0)(x_k - x_1)\cdots(x_k - x_{k-1})},
$$

pero esta fracción es exactamente la definición de la **diferencia dividida**:

$$
a_k = f[x_0, x_1, \dots, x_k].
$$

$\blacksquare$

:::
:::


::: {.callout-note title="Teorema 7"}

- Sea $f \in C[a,b]$.
- Sean $x_0, x_1, \ldots, x_n$, $(n+1)$ nodos distintos en $[a,b]$.

Entonces el polinomio de grado menor que coincide con $f$ y $f'$ en $x_0, x_1, \ldots, x_n$:

- Tiene grado $2n+1$.
- Está dado por

$$
H_{2n+1}(x) = \sum_{j=0}^{n} f(x_j) H_{nj}(x) + \sum_{j=0}^{n} f'(x_j) \widetilde{H}_{nj}(x),
$$

donde

$$
H_{nj}(x) = \big[1 - 2(x - x_j)L'_{nj}(x_j)\big]L_{nj}^2(x),
$$

y

$$
\widetilde{H}_{nj}(x) = (x - x_j) L_{nj}^2(x).
$$

- Además, el error absoluto es:

$$
\left| f(x) - H_{2n+1}(x) \right| = \left| \frac{(x - x_0)^2 \cdots (x - x_n)^2}{(2n+2)!} f^{(2n+2)}(\xi) \right|, \quad \text{con } \xi \in ]a, b[.
$$

::: {.callout-caution collapse="true" title="Prueba"}


- Se debe demostrar que $H_{2n+1}(x_i) = f(x_i)$ para todo $i = 0, 1, \ldots, n$. Para ver esto, recordemos que:

$$
L_{nj}(x_i) =
\begin{cases}
0 & \text{si } i \ne j \\
1 & \text{si } i = j
\end{cases}
$$

de donde, cuando $i \ne j$:

$$
H_{nj}(x_i) = 0 \quad \text{y} \quad \widetilde{H}_{nj}(x_i) = 0.
$$

Mientras que:

$$
H_{ni}(x_i) = [1 - 2(x_i - x_i)L'_{ni}(x_i)] \cdot 1 = 1,
$$

$$
\widetilde{H}_{ni}(x_i) = (x_i - x_i) \cdot 1^2 
$$

Luego:

$$
H_{2n+1}(x_i) = \sum_{\substack{j = 0 \\ j \ne i}}^n f(x_j) \cdot 0 + f(x_i) \cdot 1 + \sum_{j=0}^n f'(x_j) \cdot 0 = f(x_i).
$$

Por lo tanto:

- $H_{2n+1}(x_i) = f(x_i)$ para $i = 0, 1, 2, \ldots, n$.

- Se debe demostrar que $H'_{2n+1}(x_i) = f'(x_i)$ para todo $i = 0, 1, \ldots, n$.

Nótese que $L_{nj}(x)$ es un factor de $H'_{nj}(x)$, lo cual implica que $H'_{nj}(x_i) = 0$ cuando $i \ne j$.

Además, si $i = j$:

\begin{align*}
H'_{ni}(x_i) &= -2L'_{ni}(x_i)L^2_{ni}(x_i) + [1 - 2(x_i - x_i)L'_{ni}(x_i)] \cdot 2 \cdot L_{ni}(x_i)L'_{ni}(x_i) \\
&= -2L'_{ni}(x_i) + 2L'_{ni}(x_i) \\
&= 0.
\end{align*}

Por lo tanto, $H'_{nj}(x_i) = 0$ para todo $i = 0, 1, 2, \ldots, n$ y para todo $j = 0, 1, 2, \ldots, n$.

Además:

$$
\widetilde{H}_{nj}(x_i) = L^2_{nj}(x_i) + (x_i - x_j)L'_{nj}(x_j) \cdot 2 \cdot L_{nj}(x_i)L'_{nj}(x_i),
$$

de donde:

$$
\widetilde{H}'_{nj}(x_i) =
\begin{cases}
0 & \text{si } i \ne j \\
1 & \text{si } i = j
\end{cases}
$$

por lo tanto:

$$
\widetilde{H}'_{2n+1}(x_i) = \sum_{j=0}^n f(x_j) \cdot 0 + \sum_{\substack{j = 0 \\ j \ne i}}^n f'(x_j) \cdot 0 + f'(x_i) \cdot 1 = f'(x_i).
$$

es decir:

$$
H'_{2n+1}(x_i) = f'(x_i) \quad \text{para } i = 0, 1, 2, \ldots, n.
$$

- 
Sea $H(x)$ y $\widetilde{H}(x)$ dos polinomios de grado a lo sumo $2n+1$ que satisfacen:

$$
H(x_i) = \widetilde{H}(x_i) = f(x_i), \quad H'(x_i) = \widetilde{H}'(x_i) = f'(x_i), \quad \text{para } i = 0, 1, \ldots, n.
$$

Definamos el polinomio:

$$
R(x) = H(x) - \widetilde{H}(x).
$$

Entonces $R(x)$ es un polinomio de grado a lo sumo $2n+1$, y:

- $R(x_i) = H(x_i) - \widetilde{H}(x_i) = 0$,
- $R'(x_i) = H'(x_i) - \widetilde{H}'(x_i) = 0$,

para todos $i = 0, 1, \ldots, n$.

Es decir, $R(x)$ tiene **$2(n+1)$ ceros** (porque cada condición en un punto $x_i$ impone dos condiciones linealmente independientes: una en valor y otra en derivada).

Pero el grado de $R(x)$ es como máximo $2n+1$, y un polinomio no nulo de grado $d$ no puede tener más de $d$ ceros (contando multiplicidades).

Como $R(x)$ tiene más ceros que su grado, se concluye que:

$$
R(x) \equiv 0,
$$

es decir:

$$
H(x) = \widetilde{H}(x) \quad \text{para todo } x.
$$

$\blacksquare$
:::
:::

::: {.callout-note title="Lema 1"}

Si $f \in C^n[a, b]$ y $x_0, x_1, \dots, x_n$ son los $(n+1)$ nodos distintos en $[a,b]$, entonces:  
existe $\xi \in ]a, b[$ tal que:

$$
f[x_0, x_1, \dots, x_n] = \frac{f^{(n)}(\xi)}{n!}.
$$

::: {.callout-caution collapse="true" title="Prueba"}


Consideremos el polinomio interpolador de Newton de grado $n$, que interpola a $f$ en los nodos $x_0, \dots, x_n$:

$$
P_n(x) = \sum_{k=0}^n f[x_0, \dots, x_k] \prod_{j=0}^{k-1}(x - x_j).
$$

Sea el **polinomio del error**:

$$
R_n(x) = f(x) - P_n(x).
$$

Sabemos por teoría del error de interpolación que:

$$
R_n(x) = \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \prod_{j=0}^n (x - x_j),
$$

para algún $\xi_x$ entre el menor y el mayor de los puntos $x_j$ y $x$.

Ahora consideremos la función:

$$
F(x) = f(x) - Q(x),
$$

donde $Q(x)$ es el polinomio de grado $n-1$ tal que $Q(x_i) = f(x_i)$ para $i = 0, \dots, n-1$. Entonces $F(x)$ es una función que coincide con $f$ en los primeros $n$ nodos, pero no necesariamente en el último.

Aplicamos el **Teorema de Rolle generalizado** a la función:

$$
g(x) = f(x) - P_n(x),
$$

la cual se anula en los puntos $x_0, \dots, x_n$, ya que $P_n(x_j) = f(x_j)$. Como $f \in C^n[a,b]$, entonces $g \in C^n[a,b]$ y se anula en $n+1$ puntos.

Por el teorema, existe $\xi \in (a,b)$ tal que:

$$
g^{(n)}(\xi) = 0.
$$

Pero como $P_n(x)$ es de grado $n$, su derivada de orden $n$ es constante:

$$
P_n^{(n)}(x) = n! \cdot f[x_0, x_1, \dots, x_n],
$$

y:

$$
g^{(n)}(x) = f^{(n)}(x) - P_n^{(n)}(x) = f^{(n)}(x) - n! \cdot f[x_0, \dots, x_n].
$$

Entonces, si $g^{(n)}(\xi) = 0$:

$$
f^{(n)}(\xi) = n! \cdot f[x_0, \dots, x_n] \quad \Rightarrow \quad f[x_0, \dots, x_n] = \frac{f^{(n)}(\xi)}{n!}.
$$
$\blacksquare$
:::
:::


# Ejercicio 2

::: {.callout-note title="Instrucción del ejercicio 2"}

Implemente en R los algoritmos de interpolación polinómica vistos en clase.  
Los métodos que se deben implementar son:

a) Interpolar $f(x)$ usando el polinomio de Lagrange con el algoritmo de Neville.  

b) Interpolar $f(x)$ usando el polinomio de Lagrange con el algoritmo de diferencias divididas de Newton.  

c) Interpolar $f(x)$ usando el polinomio de Hermite con el algoritmo de diferencias divididas de Newton.  

d) Interpolar $f(x)$ usando el “Splines” cúbicos naturales y sujetos.  

Luego en general programe una función que permita graficar el polinomio de interpolación y la función correspondiente (si la hay).

:::

**Solución**
**Neville**
```{r}
#| code-fold: true
# Neville: interpolacion en un punto x a partir de un vector de nodos (xi) y otro de valores (f(xi))

# Retorna una lista con el valor interpolado y la matriz completa Q (la que posee todos los polinomios utilizados para la construccion del polinomio completo)

neville <- function(nodos, valores, x) {
  stopifnot(is.numeric(nodos),
            is.numeric(valores),
            length(nodos) == length(valores))
  n <- length(nodos)
  Q <- matrix(NA_real_, nrow = n, ncol = n)
  
  # Columna inicial con valores de Y
  Q[, 1] <-  valores
  
  # Construccion de la tabla de Neville
  for (i in 2:n) {
    for (j in 2:i) {
      numerador <- ((x - nodos[i - j + 1]) * Q[i, j - 1] - (x - nodos[i]) * Q[i -
                                                                                1, j - 1])
      denominador <- nodos[i] - nodos[i - j + 1]
      Q[i, j] <-  numerador / denominador
    }
  }
  return(list(valor = Q[n, n], tabla = Q))
}
```
**Lagrange por diferencias divididas de Newton**
```{r}
#| code-fold: true

# Lagrange.Newton: interpolacion en un punto x function# Lagrange.Newton: interpolacion en un punto x a partir de un vector de nodos y otro de valores

# Retorna una lista con el valor interpolado, la matriz para la construccion de los coeficientes, y un vector de los coeficientes del polinomio de lagrange

lagrange.newton <- function(nodos, valores, x) {
  stopifnot(is.numeric(nodos),
            is.numeric(valores),
            length(nodos) == length(valores))
  n <- length(nodos)
  Q <- matrix(NA_real_, nrow = n, ncol = n)
  
  Q[, 1] <- valores
  
  # Construccion de la tabla de diferencias de Newton
  for (i in 2:n) {
    for (j in 2:i) {
      numerador <- Q[i, j - 1] - Q[i - 1, j - 1]
      denominador <- nodos[i] - nodos[i - j + 1]
      Q[i, j] <-  numerador / denominador
    }
  }
  coeficientes <- diag(Q)
  
  valor = Q[1, 1]
  producto = 1
  
  for (i in 2:n) {
    producto <- producto * (x - nodos[i - 1])
    valor <- valor + coeficientes[i] * producto
  }
  return(list(
    valor = valor,
    tabla = Q,
    coeficientes = coeficientes
  ))
}
```
**Hermite por diferencias divididas de Newton**
```{r}
#| code-fold: true

# Hermite.newton: interpolacion en un punto x a partir de un vector de nodos, otro de valores y otro de derivadas

# Retorna una lista con el valor interpolado, la matriz para la construccion de los  y un vector de los coeficientes

hermite.newton <- function(nodos, valores, derivadas, x) {
  stopifnot(
    is.numeric(nodos),
    is.numeric(valores),
    is.numeric(derivadas),
    length(nodos) == length(valores),
    length(nodos) == length(derivadas)
  )
  n <- length(nodos)
  
  Z <- numeric(2 * n)
  Q <- matrix(0, nrow = 2 * n, ncol = 2 * n)
  
  
  # Set-up inicial de la matriz
  for (i in 1:n) {
    z0 <- 2 * i - 1
    z1 <- 2 * i
    Z[z0] <- nodos[i]
    Z[z1] <- nodos[i]
    Q[z0, 1] <- valores[i]
    Q[z1, 1] <- valores[i]
    Q[z1, 2] <- derivadas[i]
    if (i != 1) {
      Q[z0, 2] <- (Q[z0, 1] - Q[z0 - 1, 1]) / (Z[z0] - Z[z0 - 1])
    }
  }
  # Rellenar el resto de la matriz a partir de estos valores
  for (i in 3:(2 * n)) {
    for (j in 3:i) {
      Q[i, j] <- (Q[i, j - 1] - Q[i - 1, j - 1]) / (Z[i] - Z[i - j + 1])
    }
  }
  
  coeficientes <- diag(Q)
  
  valor <- Q[1, 1]
  producto <- 1
  
  for (i in 2:(2 * n)) {
    producto <- producto * (x - Z[i - 1])
    valor <- valor + coeficientes[i] * producto
  }
  return(list(
    valor = valor,
    tabla = Q,
    coeficientes = coeficientes
  ))
}
```
**Splines cubicos naturales**
```{r}
#| code-fold: true

# spline.natural: funcion que calcula la interpolacion por splines a partir de unos nodos y sus valores

# Retorna los valores de los coeficientes a, b, c, d de cada una de las n-1 ecuaciones generadas
spline.natural <- function(nodos, valores, x) {
  # Note que los valores de a corresponden a los valores de los nodos en la funcion, por lo que cuando aparezca el vector "valores" se debe entender que equivale al vector "a"
  n <- length(nodos)
  
  h <- numeric(n - 1)
  alfa <- numeric(n - 1)
  alfa[1] <- 0
  
  # Paso 1 y 2: definir los h's y alfas
  for (i in 1:(n - 1)) {
    h[i] <- nodos[i + 1] - nodos[i]
    if (i != 1) {
      alfa[i] <- (3 / h[i]) * (valores[i + 1] - valores[i]) - (3 / h[i - 1]) *
        (valores[i] - valores[i - 1])
    }
  }
  
  #Paso 3: definir valores iniciales de l, m, y z
  l <- numeric(n) # creo que el tamano de esto puede ser n-1
  l[1] <- 1
  m <- numeric(n - 1)
  m[1] <- 0
  z <- numeric(n) # creo que el tamano de esto puede ser n-1
  z[1] <- 0
  
  # Paso 4: rellenar vectores l, m, z
  for (i in 2:(n - 1)) {
    l[i] <- 2 * (nodos[i + 1] - nodos[i - 1]) - h[i - 1] * m[i - 1]
    m[i] <- h[i] / l[i]
    z[i] <- (alfa[i] - h[i - 1] * z[i - 1]) / l[i]
  }
  
  # Paso 5: definir valores finales
  l[n] <- 1 #creo que esto no hace falta
  z[n] <- 0 #esto tampoco
  c <- numeric(n)
  c[n] <- 0
  b <- numeric(n)
  d <- numeric(n)
  
  # Paso 6: sustitucion hacia atras
  for (j in (n - 1):1) {
    c[j] <- z[j] - m[j] * c[j + 1]
    b[j] <- (valores[j + 1] - valores[j]) / h[j] - (h[j] / 3) * (c[j + 1] +
                                                                   2 * c[j])
    d[j] <- (c[j + 1] - c[j]) / (3 * h[j])
  }
  
  # Paso extra: evaluar la interpolacion en el punto x especificado
  
  ## Encontramos los dos nodos que estan prensando al intervalo
  indice <- NULL
  for (i in 1:(n - 1)) {
    if (x >= nodos[i] && x < nodos[i + 1]) {
      indice <- i
    }
  }
  if(x == nodos[n]){
    indice <- n
  }
  if (is.null(indice)) {
    return("El valor de interpolacion debe estar entre dos nodos")
  }
  ## evaluamos en la funcion asociada
  
  valor <- valores[indice] + b[indice] * (x - nodos[indice]) + c[indice] * (x - nodos[indice])^2 + d[indice] * (x - nodos[indice])^3
  
  return(list(
    a = valores,
    b = b,
    c = c,
    d = d,
    valor = valor
  ))
}
```
**Splines cubicos sujetos**
```{r}
#| code-fold: true

# spline.sujeto: funcion que calcula la interpolacion por splines a partir de unos nodos y sus valores

# Retorna los valores de los coeficientes a, b, c, d de cada una de las n-1 ecuaciones generadas
spline.sujeto <- function(nodos, valores, derivadas, x) {
  # Note que los valores de a corresponden a los valores de los nodos en la funcion, por lo que cuando aparezca el vector "valores" se debe entender que equivale al vector "a"
  stopifnot(length(derivadas) == 2)
  n <- length(nodos)
  
  h <- numeric(n - 1)
  alfa <- numeric(n)
  
  # Paso 1 y 2: definir los h's y alfas
  for (i in 1:(n - 1)) {
    h[i] <- nodos[i + 1] - nodos[i]
    if (i != 1) {
      alfa[i] <- (3 / h[i]) * (valores[i + 1] - valores[i]) - (3 / h[i - 1]) *
        (valores[i] - valores[i - 1])
    }
  }
  
  alfa[1] <- 3 * ((valores[2] - valores[1]) / h[1] - derivadas[1])
  alfa[n] <- 3 * (derivadas[2] - (valores[n] - valores[n - 1]) / h[n - 1])
  
  #Paso 3: definir valores iniciales de l, m, y z
  l <- numeric(n) # creo que el tamano de esto puede ser n-1
  l[1] <- 2 * h[1]
  m <- numeric(n - 1)
  m[1] <- 1 / 2
  z <- numeric(n) # creo que el tamano de esto puede ser n-1
  z[1] <- alfa[1] / l[1]
  
  # Paso 4: rellenar vectores l, m, z
  for (i in 2:(n - 1)) {
    l[i] <- 2 * (nodos[i + 1] - nodos[i - 1]) - h[i - 1] * m[i - 1]
    m[i] <- h[i] / l[i]
    z[i] <- (alfa[i] - h[i - 1] * z[i - 1]) / l[i]
  }
  
  # Paso 5: definir valores finales
  l[n] <- h[n - 1] * (2 - m[n - 1])
  z[n] <- (alfa[n] - h[n - 1] * z[n - 1]) / l[n]
  c <- numeric(n)
  c[n] <- z[n]
  b <- numeric(n)
  d <- numeric(n)
  
  # Paso 6: sustitucion hacia atras
  for (j in (n - 1):1) {
    c[j] <- z[j] - m[j] * c[j + 1]
    b[j] <- (valores[j + 1] - valores[j]) / h[j] - (h[j] / 3) * (c[j + 1] + 2 * c[j])
    d[j] <- (c[j + 1] - c[j]) / (3 * h[j])
  }
  
  # Paso extra: evaluar la interpolacion en el punto x especificado
  
  ## Encontramos los dos nodos que estan prensando al intervalo
  indice <- NULL
  for (i in 1:(n - 1)) {
    if (x >= nodos[i] && x < nodos[i + 1]) {
      indice <- i
    }
  }
  if (x == nodos[n]) {
    indice <- n
  }
  if (is.null(indice)) {
    return("El valor de interpolacion debe estar entre dos nodos")
  }
  ## evaluamos en la funcion asociada
  
  valor <- valores[indice] + b[indice] * (x - nodos[indice]) + c[indice] * (x - nodos[indice])^2 + d[indice] * (x - nodos[indice])^3
  
  return(list(
    a = valores,
    b = b,
    c = c,
    d = d,
    valor = valor
  ))
}
```
**Funcion de graficacion**
```{r}
#| message: false
#| warning: false
#| code-fold: true

library(tidyverse)

graficar.polinomio <- function(nodos,
                               a,
                               b,
                               metodo,
                               f = NULL,
                               valores = NULL,
                               df = NULL,
                               derivadas = NULL,          
                               derivadas.clamped = NULL) {

  stopifnot(is.numeric(nodos), length(nodos) >= 2)

  # Validación: exactamente uno de f o valores
  if (is.null(f) == is.null(valores)) {
    stop("Debe proveer exactamente uno: 'f' (función) o 'valores' (numérico).")
  }

  # Valores en nodos
  if (!is.null(f)) {
    stopifnot(is.function(f))
    valores_nodos <- f(nodos)
  } else {
    stopifnot(is.numeric(valores), length(valores) == length(nodos))
    valores_nodos <- valores
  }

  # ---- Derivadas en nodos (si aplica) ----
  derivadas_nodos <- NULL

  # Si llegan ambos, priorizamos 'derivadas' y avisamos
  if (!is.null(df) && !is.null(derivadas)) {
    warning("Se pasaron 'df' y 'derivadas'; se usará 'derivadas'.")
  }

  if (!is.null(derivadas)) {
    stopifnot(is.numeric(derivadas), length(derivadas) == length(nodos))
    derivadas_nodos <- derivadas
  } else if (!is.null(df)) {
    if (is.function(df)) {
      derivadas_nodos <- df(nodos)
    } else if (is.numeric(df)) {
      stopifnot(length(df) == length(nodos))
      derivadas_nodos <- df
    } else {
      stop("`df` debe ser función o vector numérico de derivadas en los nodos.")
    }
  }

  # Wrapper vectorizado para el método (con o sin derivadas)
  if (!is.null(derivadas_nodos)) {
    H <- function(x)
      vapply(x, function(xx)
        metodo(nodos, valores_nodos, derivadas_nodos, xx)$valor, numeric(1))
  } else {
    if (is.null(derivadas.clamped)) {
      H <- function(x)
        vapply(x, function(xx)
          metodo(nodos, valores_nodos, xx)$valor, numeric(1))
    } else {
      H <- function(x)
        vapply(x, function(xx)
          spline.sujeto(nodos, valores_nodos, derivadas.clamped, xx)$valor, numeric(1))
    }
  }

  # Malla y data frames
  xi <- seq(a, b, length.out = 400)
  df_plot <- data.frame(
    x  = xi,
    Hx = H(xi),
    fx = if (!is.null(f)) f(xi) else NA_real_
  )
  df_nodos <- data.frame(x = nodos, y = valores_nodos)

  # Gráfico
  p <- ggplot(df_plot, aes(x = x))
  if (!is.null(f)) {
    p <- p +
      geom_line(aes(y = fx, color = "Original"), linewidth = 1) +
      geom_line(aes(y = Hx, color = "Interpolación"),
                linewidth = 1, linetype = "dashed") +
      scale_color_manual(values = c("Original" = "blue", "Interpolación" = "red"))
  } else {
    p <- p +
      geom_line(aes(y = Hx, color = "Interpolación"), linewidth = 1) +
      scale_color_manual(values = c("Interpolación" = "red"))
  }

  p +
    geom_point(data = df_nodos, aes(x = x, y = y),
               shape = 21, size = 3, fill = "white") +
    labs(title = paste0("Interpolación por ", deparse(substitute(metodo))),
         y = "Valor", color = "Serie") +
    theme_minimal(base_size = 14)
}

```
**Pruebas**
```{r}
#| code-fold: true

f <- function(x) log(x)
df <- function(x) 1/x
nodos <- c(0.1, 0.5, 1, 1.5, 2)
graficar.polinomio(nodos, nodos[1], nodos[length(nodos)], neville, f)
graficar.polinomio(nodos, nodos[1], nodos[length(nodos)], lagrange.newton, f)
graficar.polinomio(nodos, nodos[1], nodos[length(nodos)], hermite.newton, f = f, df = df)
graficar.polinomio(nodos, nodos[1], nodos[length(nodos)], spline.natural, f)
graficar.polinomio(nodos, nodos[1], nodos[length(nodos)], spline.sujeto, f = f, derivadas.clamped = c(df(nodos[1]), df(nodos[length(nodos)])))

```





# Ejercicio 3

::: {.callout-note title="Instrucción del ejercicio 3"}

Para el polinomio de Bernstein $B_n(x)$ hacer lo siguiente:

a) Demostrar que para $k \leq n$ se tiene  

$$
\binom{n-1}{k-1} = \frac{k}{n}\binom{n}{k}.
$$

b) Pruebe que, para todo $n \in \mathbb{N}$  

$$
1 = \sum_{k=0}^n \binom{n}{k} x^k (1-x)^{n-k}.
$$

c) Use (b) y (c) para probar que para $f(x) = x^2$  

$$
B_n(x) = \binom{n-1}{n} x^2 + \frac{1}{n}x.
$$

:::

**Solución**



# Ejercicio 4

::: {.callout-note title="Instrucción del ejercicio 4"}

Dada la siguiente tabla de datos para $f(x)$:

| $x$  | $f(x)$     |
|------|------------|
| 0.2  | 0.9798652  |
| 0.4  | 0.9177710  |
| 0.6  | 0.8080348  |
| 0.8  | 0.6386093  |
| 1.0  | 0.3843735  |

Aproxime $f(0.5)$ usando el procedimiento **Neville**.

:::

**Solución**

```{r}
#| code-fold: true
neville(c(0.2, 0.4, 0.6, 0.8, 1.0), c(0.9798652, 0.9177710, 0.8080348, 0.6386093, 0.3843735), 0.5)
```


# Ejercicio 5

::: {.callout-note title="Instrucción del ejercicio 5"}

a) Use el algoritmo de Neville para aproximar $f(1.03)$ con $P_{0,1,2}$ para la función  
$$f(x) = 3x e^x - e^{2x}$$  
usando $x_0 = 1$, $x_1 = 1.05$ y $x_2 = 1.07$.

b) Suponga que la aproximación en (a) no es suficientemente exacta. Calcule $P_{0,1,2,3}$ donde $x_3 = 1.04$.

c) Compare el error real en (a) y (b) con la cota del error teórica según los teoremas vistos en clase.

:::

**Solución**

a)
```{r}
#| code-fold: true
f <- function(x) 3*x*exp(x) - exp(2*x)
nodos <- c(1, 1.05, 1.07)
valores <- f(nodos)

valor.a <- neville(nodos, valores, 1.03)$valor
valor.a
```
b)
```{r}
#| code-fold: true
nodos <- c(nodos, 1.04)
valores <- f(nodos)

valor.b <- neville(nodos, valores, 1.03)$valor
valor.b
```
c) 
```{r}
#| code-fold: true
error.real.a <- abs(valor.a-f(1.03))
error.real.a

error.real.b <- abs(valor.b-f(1.03))
error.real.b

library(Deriv)

f3 <- Deriv(f, x = "x", nderiv = 3)
f4 <- Deriv(f, x = "x", nderiv = 4)

intervalo <- seq(1, 1.07, length.out = 1000)
max_f3 <- max(abs(sapply(intervalo, f3)))
max_f4 <- max(abs(sapply(intervalo, f4)))

producto.a <- prod(abs(1.03 - c(1, 1.05, 1.07)))
producto.b <- prod(abs(1.03 - c(1, 1.05, 1.07, 1.04)))

# Cotas teóricas del error
error.teorico.a <- max_f3 / factorial(3) * producto.a
error.teorico.b <- max_f4 / factorial(4) * producto.b

error.teorico.a
error.teorico.b
```

# Ejercicio 6

::: {.callout-note title="Instrucción del ejercicio 6"}

Repita el ejercicio anterior usando el polinomio de interpolación de Hermite, compare resultados.

:::

**Solución**

a)
```{r}
#| code-fold: true
f <- function(x) 3*x*exp(x) - exp(2*x)
df <- function(x) 3*x*exp(x) + 3*exp(x) -2*exp(2*x)
nodos <- c(1, 1.05, 1.07)
valores <- f(nodos)
derivadas <- df(nodos)

valor.a <- hermite.newton(nodos, valores, derivadas, 1.03)$valor
valor.a
```
b)
```{r}
#| code-fold: true
nodos <- c(nodos, 1.04)
valores <- f(nodos)
derivadas <- df(nodos)

valor.b <- hermite.newton(nodos, valores, derivadas, 1.03)$valor
valor.b
```
c) 
```{r}
#| code-fold: true
error.real.a <- abs(valor.a-f(1.03))
error.real.a

error.real.b <- abs(valor.b-f(1.03))
error.real.b


grid <- seq(1.00, 1.07, length.out = 2000)

# Caso (a): 3 nodos
m_a <- 2*length(c(1, 1.05, 1.07))  # orden 6
f6  <- Deriv(f, x="x", nderiv = m_a)
max_f6 <- max(abs(sapply(grid, f6)))
prod_a <- prod((1.03 - c(1, 1.05, 1.07))^2)
error.teorico.a <- max_f6 / factorial(m_a) * prod_a
error.teorico.a

# Caso (b): 4 nodos
m_b <- 2*length(c(1, 1.05, 1.07, 1.04))  # orden 8
f8  <- Deriv(f, x="x", nderiv = m_b)
max_f8 <- max(abs(sapply(grid, f8)))
prod_b <- prod((1.03 - c(1, 1.05, 1.07, 1.04))^2)
error.teorico.b <- max_f8 / factorial(m_b) * prod_b
error.teorico.b
```


# Ejercicio 7

::: {.callout-note title="Instrucción del ejercicio 7"}

Use el algoritmo de Diferencias Divididas para construir el polinomio interpolante de grado 4 según la siguiente tabla:

| $x$  | $f(x)$     |
|------|------------|
| 0.0  | $-7.00000$ |
| 0.1  | $-5.89483$ |
| 0.3  | $-5.65014$ |
| 0.6  | $-5.17788$ |
| 1.0  | $-4.28172$ |

Grafique este polinomio.

:::

**Solución**
```{r}
nodos <- c(0, 0.1, 0.3, 0.6, 1)
valores <- c(-7, -5.89483, -5.65014, -5.17788, -4.28172)

lagrange.newton(nodos, valores, 1)
```

A partir de lo obtenido por el algoritmo de diferencias divididas de Newton, se obtiene que el polinomio de grado 4 que interpola a f(x) es:

$P_4(x) = -7 + 11.05170x - 32.76083x(x-0.1) + 55.77056x(x-0.1)(x-0.3) - 55.49254x(x-0.1)(x-0.3)(x - 0.6)$

```{r}
#| code-fold: true
graficar.polinomio(nodos, 0, 1, lagrange.newton, valores = valores)
```


# Ejercicio 8

::: {.callout-note title="Instrucción del ejercicio 8"}

Use el algoritmo de Hermite para construir el polinomio interpolante de Hermite dada la siguiente tabla:

| $x$  | $f(x)$     | $f'(x)$    |
|------|------------|------------|
| 0.2  | 0.9798652  | 0.20271    |
| 0.4  | 0.9177710  | 0.42279    |
| 0.6  | 0.8080348  | 0.68414    |
| 0.8  | 0.6386093  | 1.02964    |
| 1.0  | 0.3843735  | 1.55741    |

Grafique este polinomio.

:::

**Solución**

```{r}
#| code-fold: true
nodos     <- c(0.2, 0.4, 0.6, 0.8, 1.0)
valores   <- c(0.9798652, 0.9177710, 0.8080348, 0.6386093, 0.3843735)
derivadas <- c(0.20271,   0.42279,   0.68414,   1.02964,   1.55741)

hermite.newton(nodos, valores, derivadas, 0.2)
```
```{r}
#| code-fold: true
graficar.polinomio(nodos, 0.2, 1, hermite.newton, valores = valores, derivadas = derivadas)
```


# Ejercicio 9

::: {.callout-note title="Instrucción del ejercicio 9"}

Use el algoritmo de Diferencias Divididas para calcular el polinomio de interpolación de Lagrange $p(x)$ de cuarto grado para:

$$
f(x) = x^3 \sin(x)
$$

con nodos $x_0 = 1$, $x_1 = 2$, $x_2 = 3$, $x_3 = 4$ y $x_4 = 5$.

Grafique en un mismo plano $f(x)$ y $p(x)$ y luego imprima.

:::

**Solución**



# Ejercicio 10

::: {.callout-note title="Instrucción del ejercicio 10"}

Probar que los polinomios $L_k(x)$ vistos en clase se pueden expresar de la forma:

$$
L_k(x) = \frac{\psi(x)}{(x - x_k)\psi'(x_k)}
$$

donde:

$$
\psi(x) = \prod_{j=0}^n (x - x_j)
$$

y que por lo tanto el polinomio interpolante de Lagrange se puede expresar como:

$$
p(x) = \psi(x) \sum_{k=0}^n \frac{f(x_k)}{(x - x_k)\psi'(x_k)}.
$$

:::

**Solución**


Partimos de la definición vista en clase del polinomio de Lagrange:

$$
L_k(x) = \prod_{\substack{j = 0 \\ j \ne k}}^n \frac{x - x_j}{x_k - x_j}
$$

Ahora definimos el polinomio:

$$
\psi(x) = \prod_{j=0}^n (x - x_j)
$$

Este se puede factorizar como:

$$
\psi(x) = (x - x_k) \prod_{\substack{j=0 \\ j \ne k}}^n (x - x_j)
\quad \Rightarrow \quad
\prod_{\substack{j=0 \\ j \ne k}}^n (x - x_j) = \frac{\psi(x)}{x - x_k}
$$

También observamos que la derivada de $\psi(x)$ evaluada en $x_k$ es:

$$
\psi'(x_k) = \prod_{\substack{j = 0 \\ j \ne k}}^n (x_k - x_j)
$$

ya que al derivar el producto total y evaluar en $x_k$, solo sobrevive el término en el que se deriva $(x - x_k)$.

::: {.callout-caution collapse="true" title="Demostración de $\psi'(x)$ por inducción"}

Queremos probar que si definimos el polinomio:

$$
\psi(x) = \prod_{j=0}^n (x - x_j)
$$

entonces, para cualquier $k \in \{0, 1, \dots, n\}$, se cumple:

$$
\psi'(x_k) = \prod_{\substack{j=0 \\ j \ne k}}^n (x_k - x_j)
$$

Esta es la derivada del producto evaluada en uno de los nodos $x_k$. Usaremos **inducción matemática sobre $n$**.

---

**Paso base: $n = 1$**

$$
\psi(x) = (x - x_0)(x - x_1)
$$

Entonces su derivada es:

$$
\psi'(x) = (x - x_0)'(x - x_1) + (x - x_0)(x - x_1)' = (x - x_1) + (x - x_0)
$$

Evaluamos en $x = x_0$:

$$
\psi'(x_0) = (x_0 - x_1) + 0 = x_0 - x_1 = \prod_{\substack{j=0 \\ j \ne 0}}^1 (x_0 - x_j)
$$

Y en $x = x_1$:

$$
\psi'(x_1) = 0 + (x_1 - x_0) = x_1 - x_0 = \prod_{\substack{j=0 \\ j \ne 1}}^1 (x_1 - x_j)
$$

Por tanto, el paso base se cumple.

---

**Paso inductivo: suponer cierto para $n$, probar para $n+1$**

Supongamos que para:

$$
\psi_n(x) = \prod_{j=0}^n (x - x_j)
$$

se cumple:

$$
\psi_n'(x_k) = \prod_{\substack{j=0 \\ j \ne k}}^n (x_k - x_j)
$$

Queremos probar que para:

$$
\psi_{n+1}(x) = \psi_n(x)(x - x_{n+1})
$$

se cumple:

$$
\psi_{n+1}'(x_k) = \prod_{\substack{j=0 \\ j \ne k}}^{n+1} (x_k - x_j)
$$

Aplicamos la derivada del producto:

$$
\psi_{n+1}'(x) = \psi_n'(x)(x - x_{n+1}) + \psi_n(x)
$$

Evaluamos en $x = x_k$ con $k \le n$. Como $\psi_n(x_k) = 0$ (por definición de raíz), el segundo término desaparece:

$$
\psi_{n+1}'(x_k) = \psi_n'(x_k)(x_k - x_{n+1})
$$

Por hipótesis inductiva:

$$
\psi_n'(x_k) = \prod_{\substack{j=0 \\ j \ne k}}^n (x_k - x_j)
$$

Entonces:

$$
\psi_{n+1}'(x_k) = \left( \prod_{\substack{j=0 \\ j \ne k}}^n (x_k - x_j) \right)(x_k - x_{n+1}) 
= \prod_{\substack{j=0 \\ j \ne k}}^{n+1} (x_k - x_j)
$$

Lo cual demuestra que la fórmula también es válida para $n+1$.

---

**Conclusión:**

Por el principio de inducción matemática, se cumple que:

$$
\boxed{
\psi'(x_k) = \prod_{\substack{j=0 \\ j \ne k}}^n (x_k - x_j)
}
$$

para todo $k \in \{0, 1, \dots, n\}$.

:::

Sustituyendo todo en la fórmula original de $L_k(x)$:

$$
L_k(x) = \frac{\prod\limits_{\substack{j = 0 \\ j \ne k}}^n (x - x_j)}{\prod\limits_{\substack{j = 0 \\ j \ne k}}^n (x_k - x_j)}
= \frac{\psi(x)}{(x - x_k)\psi'(x_k)}
$$

Esto completa la prueba de la fórmula para $L_k(x)$.

Finalmente, como el polinomio interpolante de Lagrange se define como:

$$
p(x) = \sum_{k=0}^n f(x_k) L_k(x)
$$

entonces sustituyendo la expresión obtenida para $L_k(x)$:

$$
p(x) = \sum_{k=0}^n f(x_k) \frac{\psi(x)}{(x - x_k)\psi'(x_k)}
= \psi(x) \sum_{k=0}^n \frac{f(x_k)}{(x - x_k)\psi'(x_k)}
$$

# Ejercicio 11

::: {.callout-note title="Instrucción del ejercicio 11"}

Demostrar que si $f(x)$ es un polinomio de grado menor o igual a $n$, entonces el polinomio de grado menor o igual a $n$ que interpola $f(x)$ en $x_0, x_1, \ldots, x_n$ es el mismo $f(x)$.

:::

**Solución**

Sea $f(x)$ un polinomio de grado menor o igual a $n$ y $P_n(x)$ el polinomio que lo interpola en $x_0, x_1,..., x_n$. 

Note que $f^{(n+1)}(x) = 0$, pues es un polinomio de grado menor o igual a n. 

Además, se sabe que el error absoluto entre $f(x)$ y su interpolacion viene dado por:

$|f(x) - P_n(x)| = |\dfrac{f^{(n+1)}(\psi_x)}{(n+1)!}(x - x_0)(x - x_1)\cdot\cdot\cdot(x-x_n)|$, con $\psi_x \in [a,b]$, donde $[a,b]$ es el intervalo donde estamos interpolando. 

Juntando estas dos cosas, se concluye que $|f(x) - P_n(x)| = 0 \Rightarrow f(x) = P_n(x)$

$\blacksquare$

# Ejercicio 12

::: {.callout-note title="Instrucción del ejercicio 12"}

Usar el ejercicio anterior para probar que:

$$
\sum_{i=0}^n L_i(x) = 1
$$

:::

**Solución**

::: {.callout-note title="Instrucción del ejercicio 13"}

Para las siguientes funciones:

- $f(x)=3x^2\ln(x)+2x$ con nodos $x_0=1$, $x_1=1.5$, $x_2=2$, $x_3=2.5$ y $x_4=3$.
- $f(x)=x^2\sin(x)-3\cos(x)$ con nodos $x_0=1$, $x_1=2$, $x_2=3$, $x_3=4$ y $x_4=5$.
- $f(x)=x\cos(x)-2x^2+3x-1$ con nodos $x_0=1$, $x_1=2$, $x_2=3$, $x_3=4$ y $x_4=5$.

a) Encuentre el polinomio de interpolación de Lagrange $P^\star(x)$ en los nodos indicados, grafique $f(x)$ y $P^\star(x)$ en el mismo plano.

b) Encuentre el polinomio de interpolación usando Splines cúbicos $P^{\star\star}(x)$ en los nodos indicados, grafique $f(x)$ y $P^{\star\star}(x)$ en el mismo plano, luego imprima.

c) Encuentre el polinomio de interpolación de Hermite $P^{\star\star\star}(x)$ en los nodos indicados, grafique $f(x)$ y $P^{\star\star\star}(x)$ en el mismo plano.

d) Grafique $f(x)$, $P^\star(x)$, $P^{\star\star}(x)$ y $P^{\star\star\star}(x)$ en el mismo plano. ¿Qué se puede concluir?

:::

**Solución**

# Ejercicio 13

::: {.callout-note title="Instrucción del ejercicio 13"}

Para las siguientes funciones:

- $f(x)=3x^{2}\ln(x)+2x$ con nodos $x_{0}=1$, $x_{1}=1.5$, $x_{2}=2$, $x_{3}=2.5$ y $x_{4}=3$.
- $f(x)=x^{2}\sin(x)-3\cos(x)$ con nodos $x_{0}=1$, $x_{1}=2$, $x_{2}=3$, $x_{3}=4$ y $x_{4}=5$.
- $f(x)=x\cos(x)-2x^{2}+3x-1$ con nodos $x_{0}=1$, $x_{1}=2$, $x_{2}=3$, $x_{3}=4$ y $x_{4}=5$.

a) Encuentre el polinomio de interpolación de Lagrange $P^\star(x)$ en los nodos indicados, grafique $f(x)$ y $P^\star(x)$ en el mismo plano.

b) Encuentre el polinomio de interpolación usando Splines cúbicos $P^{\star\star}(x)$ en los nodos indicados, grafique $f(x)$ y $P^{\star\star}(x)$ en el mismo plano; luego imprima.

c) Encuentre el polinomio de interpolación de Hermite $P^{\star\star\star}(x)$ en los nodos indicados, grafique $f(x)$ y $P^{\star\star\star}(x)$ en el mismo plano.

d) Grafique $f(x)$, $P^\star(x)$, $P^{\star\star}(x)$ y $P^{\star\star\star}(x)$ en el mismo plano. ¿Qué se puede concluir?

:::

**Solución**

Preparación
```{r}
#| code-fold: true

# Funciones 
f1 <- function(x) 3 * x^2 * log(x) + 2 * x
f2 <- function(x) x^2 * sin(x) - 3 * cos(x)
f3 <- function(x) x * cos(x) - 2 * x^2 + 3 * x - 1

# Derivadas 
df1 <- function(x) 6 * x * log(x) + 3 * x + 2
df2 <- function(x) 2 * x * sin(x) + x^2 * cos(x) + 3 * sin(x)
df3 <- function(x) cos(x) - x * sin(x) - 4 * x + 3
```

a)

```{r}
#| code-fold: true
#| fig-cap: "Interpolación de Lagrange - Función 1"
graficar.polinomio(c(1, 1.5, 2, 2.5, 3), 1, 3, lagrange.newton, f = f1)
```
```{r}
#| code-fold: true
#| fig-cap: "Interpolación de Lagrange - Función 2"
graficar.polinomio(c(1, 2, 3, 4, 5), 1, 5, lagrange.newton, f = f2)
```
```{r}
#| code-fold: true
#| fig-cap: "Interpolación de Lagrange - Función 3"
graficar.polinomio(c(1, 2, 3, 4, 5), 1, 5, lagrange.newton, f = f3)
```
b)
```{r}
#| code-fold: true
#| fig-cap: "Interpolación por Splines naturales - Función 1"
graficar.polinomio(c(1, 1.5, 2, 2.5, 3), 1, 3, spline.natural, f = f1)
```
```{r}
#| code-fold: true
#| fig-cap: "Interpolación por Splines naturales - Función 2"
graficar.polinomio(c(1, 2, 3, 4, 5), 1, 5, spline.natural, f = f2)
```
```{r}
#| code-fold: true
#| fig-cap: "Interpolación por Splines naturales - Función 3"
graficar.polinomio(c(1, 2, 3, 4, 5), 1, 5, spline.natural, f = f3)
```
c)
```{r}
#| code-fold: true
#| fig-cap: "Interpolación de Hermite - Función 1"
graficar.polinomio(c(1, 1.5, 2, 2.5, 3), 1, 3, hermite.newton, f = f1, df = df1)
```
```{r}
#| code-fold: true
#| fig-cap: "Interpolación de Hermite - Función 2"
graficar.polinomio(c(1, 2, 3, 4, 5), 1, 5, hermite.newton, f = f2, df = df2)
```
```{r}
#| code-fold: true
#| fig-cap: "Interpolación de Hermite - Función 3"
graficar.polinomio(c(1, 2, 3, 4, 5), 1, 5, hermite.newton, f = f3, df = df3)
```
d)
```{r}
#| code-fold: true
#| fig-cap: "Comparación de métodos - Función 1"
nodos1 <- c(1, 1.5, 2, 2.5, 3)
valores1 <- f1(nodos1)
derivadas1 <- df1(nodos1)

xi <- seq(1, 3, length.out = 400)
df_comp1 <- tibble(
  x = xi,
  `f(x)` = f1(xi),
  Lagrange = vapply(xi, function(x) lagrange.newton(nodos1, valores1, x)$valor, numeric(1)),
  Hermite = vapply(xi, function(x) hermite.newton(nodos1, valores1, derivadas1, x)$valor, numeric(1)),
  Splines = vapply(xi, function(x) spline.natural(nodos1, valores1, x)$valor, numeric(1))
) |> pivot_longer(-x, names_to = "Método", values_to = "y")

ggplot(df_comp1, aes(x = x, y = y, color = Método)) +
  geom_line(linewidth = 1) +
  geom_point(data = tibble(x = nodos1, y = valores1), 
             aes(x = x, y = y, color = "Nodos"), 
             shape = 21, fill = "white", size = 2) +
  labs(title = "Comparación de métodos de interpolación - Función 1") +
  theme_minimal(base_size = 14)
```
```{r}
#| code-fold: true
#| fig-cap: "Comparación de métodos de interpolación - Función 2"

nodos2 <- c(1, 2, 3, 4, 5)
valores2 <- f2(nodos2)
derivadas2 <- df2(nodos2)

xi2 <- seq(1, 5, length.out = 400)
df_comp2 <- tibble(
  x = xi2,
  `f(x)` = f2(xi2),
  Lagrange = vapply(xi2, function(x) lagrange.newton(nodos2, valores2, x)$valor, numeric(1)),
  Hermite = vapply(xi2, function(x) hermite.newton(nodos2, valores2, derivadas2, x)$valor, numeric(1)),
  Splines = vapply(xi2, function(x) spline.natural(nodos2, valores2, x)$valor, numeric(1))
) |> pivot_longer(-x, names_to = "Método", values_to = "y")

ggplot(df_comp2, aes(x = x, y = y, color = Método)) +
  geom_line(linewidth = 1) +
  geom_point(data = tibble(x = nodos2, y = valores2),
             aes(x = x, y = y, color = "Nodos"),
             shape = 21, fill = "white", size = 2) +
  labs(title = "Comparación de métodos de interpolación - Función 2") +
  theme_minimal(base_size = 14)
```

```{r}
#| code-fold: true
#| fig-cap: "Comparación de métodos de interpolación - Función 3"

nodos3 <- c(1, 2, 3, 4, 5)
valores3 <- f3(nodos3)
derivadas3 <- df3(nodos3)

xi3 <- seq(1, 5, length.out = 400)
df_comp3 <- tibble(
  x = xi3,
  `f(x)` = f3(xi3),
  Lagrange = vapply(xi3, function(x) lagrange.newton(nodos3, valores3, x)$valor, numeric(1)),
  Hermite = vapply(xi3, function(x) hermite.newton(nodos3, valores3, derivadas3, x)$valor, numeric(1)),
  Splines = vapply(xi3, function(x) spline.natural(nodos3, valores3, x)$valor, numeric(1))
) |> pivot_longer(-x, names_to = "Método", values_to = "y")

ggplot(df_comp3, aes(x = x, y = y, color = Método)) +
  geom_line(linewidth = 1) +
  geom_point(data = tibble(x = nodos3, y = valores3),
             aes(x = x, y = y, color = "Nodos"),
             shape = 21, fill = "white", size = 2) +
  labs(title = "Comparación de métodos de interpolación - Función 3") +
  theme_minimal(base_size = 14)
```
**¿Conclusion?**

Función 1: $f(x) = 3x^2 \ln(x) + 2x$

- Los tres métodos coinciden visualmente con la función original.
- La función es suave y bien comportada en $[1, 3]$, y los nodos están bien distribuidos.
- **Todos los métodos son adecuados**; no hay oscilaciones ni errores notables.

Función 2: $f(x) = x^2 \sin(x) - 3\cos(x)$

- Se observan diferencias leves entre Lagrange y los otros métodos, especialmente en los extremos.
- **Hermite y Splines** ofrecen mejor ajuste, aprovechando la información de derivadas o la suavidad estructural.
- **Lagrange tiende a oscilar más** en funciones con más curvatura.

Función 3: $f(x) = x\cos(x) - 2x^2 + 3x - 1$

- Los tres métodos coinciden perfectamente con la función en el intervalo.
- La función es suave y casi polinómica, lo que facilita la interpolación.
- **Todos los métodos funcionan bien en este caso**.

# Ejercicio 14

::: {.callout-note title="Instrucción del ejercicio 14"}

¿Existen $a,b,c,d$ tal que la función:

$$
S(x)=
\begin{cases}
ax^3+x^2+cx, & -1\le x\le 0,\\[4pt]
bx^3+x^2+dx, & \ \ 0\le x\le 1
\end{cases}
$$

sea el spline cúbico natural que coincide con la función $f(x)=|x|$ en los nodos $-1,0,1$?

:::

**Solución**

Una de las primeras condiciones que deben ocurrir es que $S_{-1}(-1) = 1$ y $S_0(1) = 1$

\begin{equation*}
\begin{cases}
  S_{-1}(-1) =-a + 1 - c = 1\\
  S_0(1) = b + 1 + d = 1
\end{cases}
\Longrightarrow
\begin{cases}
  a = -c \\
  b = -d
\end{cases}
\end{equation*}

Por otra parte, debe suceder que $S'_{-1}(0) = S'_0(0)$

$$
3ax^2 +2x +c = 3bx^2 +2x +d \text{ en $x = 0$}\Rightarrow c = d \Rightarrow a = -c = -d = b \Rightarrow a = b
$$

Finalmente, se debe cumplir la condicion natural: $S''_{-1}(-1) = 0$ y $S''_0(1) = 0$

\begin{equation*}\begin{cases}
  6a(-1) + 2 = 0\\
  6b(1) + 2 = 0
\end{cases}
\Longrightarrow
\begin{cases}
  a = 1/3\\
  b = -1/3
\end{cases}
\Longrightarrow a = -b \Rightarrow \Leftarrow\end{equation*}

Por lo tanto, no existen $a,b,c,d$ tal que $S(x)$ sea el spline cubico natural de $|x|$ en los nodos $-1, 0, 1$

# Ejercicio 15

::: {.callout-note title="Instrucción del ejercicio 15"}

Encuentre los valores de $a,b,c,d$ y $e$ tal que la función $S(x)$ es un spline cúbico natural:

$$
S(x)=
\begin{cases}
a+b(x-1)+c(x-1)^2+d(x-1)^3, & 0\le x\le 1,\\[4pt]
(x-1)^3+ex^2-1, & 1\le x\le 2.
\end{cases}
$$

:::

**Solución**



# Ejercicio 16

::: {.callout-note title="Instrucción del ejercicio 16"}

Encuentre los valores de $a,b,c$ y $d$ tal que la función $S(x)$ es un spline cúbico y cumple que
$\displaystyle \int_{0}^{2}\!\big[S''(x)\big]^2\,dx$ es mínimo (esta condición sustituye a la condición para ser spline natural o sujeto):

$$
S(x)=
\begin{cases}
3+x-9x^3, & 0\le x\le 1,\\[4pt]
a+b(x-1)+c(x-1)^2+d(x-1)^3, & 1\le x\le 2.
\end{cases}
$$

:::

**Solución**


1) Condiciones de continuidad en $x=1$ (de $S$ y $S'$) y de empalme de $S''$:

- Para $x\le 1$:  
  $S_0(x)=3+x-9x^3,\;\; S_0'(x)=1-27x^2,\;\; S_0''(x)=-54x.$

- Para $x\ge 1$:  
  $S_1(x)=a+b(x-1)+c(x-1)^2+d(x-1)^3,$  
  $S_1'(x)=b+2c(x-1)+3d(x-1)^2,$  
  $S_1''(x)=2c+6d(x-1).$

En $x=1$:
\begin{align*}
S_0(1)=3+1-9=-5 &\Rightarrow a=-5,\\
S_0'(1)=1-27=-26 &\Rightarrow b=-26,\\
S_0''(1)=-54 = 2c &\Rightarrow c=-27.
\end{align*}

2) Minimización de la energía de curvatura:
$$
J(d)=\int_{0}^{1}\!\big[S_0''(x)\big]^2 dx+\int_{1}^{2}\!\big[S_1''(x)\big]^2 dx.
$$

El primer término no depende de $d$:
$$
\int_{0}^{1}\!\big(-54x\big)^2 dx=\frac{54^2}{3}.
$$

Para el segundo, ponga $y=x-1\in[0,1]$, con $A=-54$ y $B=6d$:
\begin{align*}
\int_{1}^{2}\!\big(-54+6d(x-1)\big)^2 dx
&=\int_{0}^{1} (A+By)^2 dy \\
&= A^2 + AB + \frac{B^2}{3}
= 2916 - 324d + 12d^2.
\end{align*}

Luego
$$
J(d)=\text{cte} + 12d^2 - 324d,
\qquad
J'(d)=24d-324=0 \Rightarrow d=\frac{324}{24}=13.5.
$$

**Resultado final:**  
$$
\boxed{\,a=-5,\quad b=-26,\quad c=-27,\quad d=13.5\,}
$$
$\blacksquare$

# Ejercicio 17

::: {.callout-note title="Instrucción del ejercicio 17"}

El objetivo de este ejercicio es estudiar e implementar un algoritmo para **Aproximación discreta por mínimos cuadrados**. Para esto:

a) El problema en general es aproximar una tabla de datos $\{(x_i,y_i)\mid i=1,2,\ldots,m\}$ por un polinomio de grado $n<m-1$ denotado por
$$
P_n(x)=\sum_{k=0}^{n} a_k x^k.
$$
La idea es encontrar constantes $\{a_k\}_{k=0}^{n}$ tal que se minimice el error:
$$
E=\sum_{i=1}^{m}\big(y_i-P_n(x_i)\big)^2.
$$
Pruebe que este mínimo se alcanza en la solución del sistema de **ecuaciones normales** (n+1)×(n+1) para las incógnitas $\{a_k\}_{k=0}^{n}$ dado por:
$$
\sum_{k=0}^{n} a_k \sum_{i=1}^{m} x_i^{\,j+k}
\;=\;
\sum_{i=1}^{m} y_i x_i^{\,j},
\qquad j=0,1,2,\ldots,n.
$$

b) Dada una tabla de datos para $f$, escriba una función en **R** que permita generar el sistema de ecuaciones normales del inciso (a).

c) Luego escriba una función en **R** que encuentre los coeficientes del polinomio de mínimos cuadrados y luego lo grafique.

d) Construir la **aproximación de mínimos cuadrados de grado 3** para la siguiente tabla y **construir el gráfico**.

| $x_i$ | $y_i$   |
|:-----:|:-------:|
| 4.0   | 102.56  |
| 4.2   | 113.18  |
| 4.5   | 130.11  |
| 4.7   | 142.05  |
| 5.1   | 167.53  |
| 5.5   | 195.14  |
| 5.9   | 224.87  |
| 6.3   | 256.73  |
| 6.8   | 299.50  |
| 7.1   | 326.72  |

:::

**Solución**
a)

Para encontrar el minimo de $E$, hay que derivarlo con respecto a cada uno de los $a_j$, con $j = 0, 1, ..., n$

$$
\dfrac{\partial E}{\partial a_j} = 2 \sum_{i = 1}^{m}{(y_i - \sum_{k = 0}^{n}{a_kx_i^k})\cdot \dfrac{-\partial}{\partial a_k}(\sum_{k = 0}^n{a_kx_i^k})}=0
$$

Note que $\dfrac{\partial}{\partial a_j}(\sum_{k = 0}^n{a_kx_i^k}) = x_i^j$

$$
\Rightarrow \dfrac{\partial E}{\partial a_j} = -2\cdot \sum_{i = 1}^m{(y_i - \sum_{k = 0}^n{a_kx_i^k})\cdot x_i^j} = 0 \\
\Rightarrow -\sum_{i = 1}^m{y_ix_i^j} + \sum_{i = 1}^m \sum_{k = 0}^n {a_kx_i^{k+j}} = 0 \\
\Rightarrow \sum_{k = 0}^n{a_k\sum_{i = 1}^m{x_i^{j+k}}} = \sum_{i = 1}^m{y_ix_i^j}
$$

b)
```{r}
#| code-fold: true

# Funcion para plantear el sistema de ecuaciones asociado al ajuste de minimos cuadrados
# Retorna matriz asociada a los coeficientes (A) y vector de solucion (B)
sistema.minimos <- function(nodos, valores, n){
  stopifnot(is.numeric(nodos), is.numeric(valores),
            length(nodos) == length(valores),
            is.numeric(n), n >= 0, n < length(nodos))
  m <- length(nodos)
  A <- matrix(NA_real_, nrow = n + 1, ncol = n + 1)
  B <- numeric(n + 1)
  for (j in 0:n){
    for (k in 0:n) {
      A[j + 1, k + 1] <- sum(nodos^(j + k)) 
    }
    B[j + 1] <- sum(nodos^(j) * valores)
  }
  return(list(A = A, B = B))
}
```
c)
```{r}
#| code-fold: true

# Funcion para encontrar coeficientes del polinomio que surge del ajuste de minimos cuadrados y hacer el grafico del mismo
ajuste.minimos.cuadrados <- function(nodos, valores, n, a, b){
  stopifnot(is.numeric(nodos), is.numeric(valores),
            length(nodos) == length(valores),
            is.numeric(a), is.numeric(b), a < b,
            is.numeric(n), n >= 0)
  sistema <- sistema.minimos(nodos, valores, n)
  
  coef <- as.numeric(solve(sistema$A, sistema$B))
  
  # Polinomio ajustado
  f_hat <- function(z) vapply(z, function(zz) sum(coef * zz^(0:n)), numeric(1))
  
  # Datos para el gráfico
  xi <- seq(a, b, length.out = 400)
  df_plot <- data.frame(x = xi, Hx = f_hat(xi))
  df_pts  <- data.frame(x = nodos, y = valores)
  
  # Gráfico 
  p <- ggplot(df_plot, aes(x = x)) +
    geom_line(aes(y = Hx, color = "Ajuste (MC)"),
              linewidth = 1, linetype = "dashed") +
    scale_color_manual(values = c("Ajuste (MC)" = "red")) +
    geom_point(data = df_pts, aes(x = x, y = y),
               shape = 21, size = 3, fill = "white") +
    labs(title = paste0("Interpolación por ajuste de\nmínimos cuadrados (grado ", n, ")"),
         y = "Valor", color = "Serie") +
    theme_minimal(base_size = 14)
  
  return(list(coeficientes = coef, f.ajuste = f_hat, grafico = p))
}
```
d)
```{r}
#| code-fold: true

nodos   <- c(4.0, 4.2, 4.5, 4.7, 5.1, 5.5, 5.9, 6.3, 6.8, 7.1)
valores <- c(102.56, 113.18, 130.11, 142.05, 167.53, 195.14, 224.87, 256.73, 299.50, 326.72)
n <- 3
a <- min(nodos)
b <- max(nodos)

x <- ajuste.minimos.cuadrados(nodos, valores, n, a, b)
x
```


# Ejercicio 18

::: {.callout-note title="Instrucción del ejercicio 18"}

El objetivo de este ejercicio es **generalizar la aproximación discreta por mínimos cuadrados**.  
Dada una función $f\in C[a,b]$, se requiere un polinomio $\tilde P_n(x)=\sum\limits_{k=0}^{n} a_k x^k$ de manera tal que las constantes $\{a_k\}_{k=0}^{n}$ minimicen el error:

$$
E=\int_a^b \big(f(x)-\tilde P_n(x)\big)^2\,dx.
$$

Pruebe que este mínimo se alcanza en la solución del sistema de **$(n+1)$ ecuaciones normales** y $(n+1)$ incógnitas $\{a_k\}_{k=0}^{n}$ dado por:

$$
\sum_{k=0}^{n} a_k \int_a^b x^{j+k}\,dx \;=\; \int_a^b x^{j} f(x)\,dx,
\qquad j=0,1,2,\ldots,n.
\tag{2}
$$

a) Dada una función $f$ escriba una función en **R** que permita **generar el sistema de ecuaciones (2)**.

b) Luego escriba una función en **R** que **encuentre los coeficientes** del polinomio $\tilde P_n(x)$ y luego lo grafique.

c) Encuentre la **aproximación polinómica** $\tilde P_n(x)$ de grado $2$, $4$ y $6$ para $f(x)=\cos(\pi x)$ en el intervalo $[-1,1]$. Además, **construya los gráficos**.

:::

**Solución**

a)

```{r}
sistema.minimos.integrados <- function(a, b, f, n){
  A <- matrix(NA_real_, nrow = n + 1, ncol = n + 1)
  B <- numeric(n + 1)
  
  for (j in 0:n) {
    for (k in 0:n) {
      A[j + 1, k + 1] <- integrate(function(x) x^(j + k), a, b)$value
    }
    B[j + 1] <- integrate(function(x) f(x) * x^j, a, b)$value
  }
  return(list(A = A, B = B))
}
```
b)
```{r}
ajuste.minimos.cuadrados.integrados <- function(a, b, f, n){
  sistema <- sistema.minimos.integrados(a, b, f, n)
  
  coef <- as.numeric(solve(sistema$A, sistema$B))
  
  # Polinomio ajustado
  f_hat <- function(z) vapply(z, function(zz) sum(coef * zz^(0:n)), numeric(1))
  
  # Datos para el gráfico
  xi <- seq(a, b, length.out = 400)
  df_plot <- data.frame(x = xi, Hx = f_hat(xi), fx = f(xi))

  # Gráfico 
  p <- ggplot(df_plot, aes(x = x)) +
    geom_line(aes(y = fx, color = "Original"), linewidth = 1) +
    geom_line(aes(y = Hx, color = "Ajuste (MC)"),
              linewidth = 1, linetype = "dashed") +
    scale_color_manual(values = c("Ajuste (MC)" = "red", "Original" = "blue")) +
    labs(title = paste0("Interpolación por ajuste de\nmínimos cuadrados (grado ", n, ")"),
         y = "Valor", color = "Serie") +
    theme_minimal(base_size = 14)
  
  invisible(list(coeficientes = coef, f_ajuste = f_hat, grafico = p))
}
```
c)

```{r}
grado.2 <- ajuste.minimos.cuadrados.integrados(-1,1, function(x) cos(pi * x),2)
grado.4 <- ajuste.minimos.cuadrados.integrados(-1,1, function(x) cos(pi * x),4)
grado.6 <- ajuste.minimos.cuadrados.integrados(-1,1, function(x) cos(pi * x),6)
```
```{r}
# Coeficientes de P2
print(grado.2$coeficientes)
print(grado.2$grafico)

# Coeficientes de P4
print(grado.4$coeficientes)
print(grado.4$grafico)

# Coeficientes de P6
print(grado.6$coeficientes)
print(grado.6$grafico)
```




# Ejercicio 19

::: {.callout-note title="Instrucción del ejercicio 19"}

a) Demuestre que el **Polinomio de Hermite** visto en clase $H_{2n+1}(x)$ es **único**.  
*Sugerencia:* Suponga que existe otro polinomio $P(x)$ que cumple las condiciones de interpolación de Hermite y considere $D=H_{2n+1}(x)-P(x)$ y $D'$ en $x_0,x_1,\ldots,x_n$.

b) Demuestre que el **error absoluto** en este caso está dado por:

$$
\big|f(x)-H_{2n+1}(x)\big| \;=\;
\left|\frac{(x-x_0)^2\cdots(x-x_n)^2}{(2n+2)!}\, f^{(2n+2)}(\xi)\right|,
\quad \text{con } \xi\in(a,b) .
$$

**Sugerencia:** Use el mismo método que usamos para demostrar la fórmula del error absoluto en el caso de Lagrange, pero con:

$$
g(t)=f(t)-H_{2n+1}(t)\;-\;
\frac{(t-x_0)^2\cdots(t-x_n)^2}{(x-x_0)^2\cdots(x-x_n)^2}
\Big[f(x)-H_{2n+1}(x)\Big].
$$

:::

**Solución**

a) Suponga que existe otro polinomio $P(x)$ que también satisface las $2(n+1)$
condiciones de interpolación de Hermite en $x_0,\dots,x_n$.  
Considere
$$
D(x)=H_{2n+1}(x)-P(x).
$$

  1. Como $H_{2n+1}$ y $P$ coinciden en valores y derivadas en cada nodo,
     $$D(x_i)=0\quad\text{y}\quad D'(x_i)=0,\qquad i=0,\dots,n.$$
     Por lo tanto, cada $x_i$ es una raíz de $D$ con multiplicidad al menos $2$.
  
  2. Luego $D$ tiene al menos $2(n+1)$ ceros **contando multiplicidades**.
     Pero $$\deg D \le \max\{\deg H_{2n+1},\deg P\}\le 2n+1$$
  
  3. El Teorema Fundamental del Álgebra (contando multiplicidades) implica que
     un polinomio no nulo de grado $\le 2n+1$ no puede tener $2(n+1)$ raíces.  
     La única posibilidad es $D\equiv 0$.

Así, $H_{2n+1}(x)\equiv P(x)$ y el polinomio de Hermite es único. 

$\blacksquare$

::: {.callout-important collapse="true" title="Comentario"}
La hipótesis de que los nodos $x_0,\dots,x_n$ son **distintos** es esencial:
garantiza que las $2(n+1)$ condiciones (valores y derivadas) son independientes.
Si algunas coincidieran, la formulación correcta requiere multiplicidades
adecuadas (nodos repetidos) y el argumento se adapta contando esas multiplicidades.
:::

b)
Defina el polinomio nodal
$$
\omega(t)=\prod_{i=0}^{n}(t-x_i)^2,
\qquad \omega(x)=\prod_{i=0}^{n}(x-x_i)^2\neq 0 \ \ (x\ne x_i).
$$
Considere, para $t\in[a,b]$,

$$
g(t) = f(t) - H_{2n+1}(t) - \frac{\omega(t)}{\omega(x)} \, [ f(x) - H_{2n+1}(x) ].
$$ {#eq-hola}

  1) Zeros de $g$ y $g'$ en los nodos
  
    Para cada $i$, como $H_{2n+1}$ interpola valores y derivadas,
  $$
  f(x_i)-H_{2n+1}(x_i)=0,\qquad f'(x_i)-H'_{2n+1}(x_i)=0.
  $$
    Además, $\omega(x_i)=0$ y $\omega'(x_i)=0$ (raíz doble). Sustituyendo en (1) se obtiene
  $$
  g(x_i)=0,\qquad g'(x_i)=0,\qquad i=0,\dots,n.
  $$
  
  2) Cero adicional en $t=x$.
  De @eq-hola se ve directamente que $g(x)=0$.
  
  3) Aplicación de Rolle generalizado (con multiplicidades).
  La función $g$ es $C^{2n+2}$ y tiene $2(n+1)$ ceros en
  $x_0,\dots,x_n$ (por multiplicidad doble) más un cero en $x$.
  Por el Teorema Generalizado de Rolle, existe $\xi\in(a,b)$ tal que
  $$
  g^{(2n+2)}(\xi)=0. 
  $${#eq-holdasa}
  
  4) Cálculo de la derivada $(2n+2)$-ésima.
  Derivando @eq-hola $2n+2$ veces,
  el término $H_{2n+1}$ desaparece (su grado $\le 2n+1$),
  y como $\omega$ es un polinomio mónico de grado $2n+2$,
  $$
  \frac{d^{\,2n+2}}{dt^{2n+2}}\omega(t)=(2n+2)!.
  $$
Así,
$$
g^{(2n+2)}(t)=f^{(2n+2)}(t)
-\frac{(2n+2)!}{\omega(x)}\,[\,f(x)-H_{2n+1}(x)\,].
$$
Evaluando en $\xi$ y usando @eq-holdasa,
$$
0=f^{(2n+2)}(\xi)
-\frac{(2n+2)!}{\omega(x)}\,[\,f(x)-H_{2n+1}(x)\,],
$$
de donde
$$
f(x)-H_{2n+1}(x)=\frac{f^{(2n+2)}(\xi)}{(2n+2)!}\,\omega(x)
=\frac{f^{(2n+2)}(\xi)}{(2n+2)!}\prod_{i=0}^{n}(x-x_i)^2.
$$

$\blacksquare$