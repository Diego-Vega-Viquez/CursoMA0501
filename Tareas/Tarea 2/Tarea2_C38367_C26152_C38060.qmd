---
title: "MA0501 – Tarea 2"
author: 
  - name: "Diego Alberto Vega Víquez - C38367" 
    email: "diegovv13@gmail.com"
  - name: "José Carlos Quintero Cedeño - C26152" 
    email: "jose.quinterocedeno@ucr.ac.cr"
  - name: "Gabriel Valverde Guzmán - C38060"
    email: "GABRIEL.VALVERDEGUZMAN@ucr.ac.cr"
date: today
lang: es
format:
  pdf:
    documentclass: article
    fontsize: 11pt
    linestretch: 1.3
    geometry:
      - top=2.5cm
      - bottom=2.5cm
      - left=2.5cm
      - right=2.5cm
      - headheight=15pt
      - footskip=1.25cm
    toc: true
    toc-depth: 1
    number-sections: false
    classoption:
      - oneside
      - titlepage 
    openany: true
    colorlinks: false   
    top-level-division: section
    include-in-header: 
      text: |
        \usepackage[most]{tcolorbox}
        \usepackage[hidelinks]{hyperref}
        \usepackage{setspace}
        \AtBeginDocument{\setstretch{1.0}} % ← interlineado
  html:
    code-annotations: hover
    toc: true
    toc-depth: 1
    toc-location: left
    toc_float: yes
    html-math-method: katex
    css: styles.css
    df_print: paged
    theme: flatly
    highlight: tango
---

\newpage

# Ejercicio 1
::: {.callout-note}
## Instrucción

Suponga que $p^*$ aproxima a $p$ con 3 dígitos significativos.  
Encuentre el intervalo en el cual $p^*$ debe estar, si:

a) $\quad p = 150$  
b) $\quad p = 900$  
c) $\quad p = 1500$  
d) $\quad p = 90$  

:::

## Solución

Vea que si $P^*$ aproxima a $P$ con 3 dígitos significativos eso significa que 

\begin{align*}
\frac{|P - P^*|}{|P|} &< 0.5 \times 10^{-t+1} \\[1ex]
|P - P^*| &< 0.5 \times 10^{-t+1}\,|P| \\[1ex]
P - 0.5 \times 10^{-t+1}\,|P| &< P^* < P + 0.5 \times 10^{-t+1}\,|P|
\end{align*}

Por lo que se puede concluir que el intervalo en el cual $p*$ debe estar es

$$
](1 - 0.5 \times 10^{-t+1})\,|P|, (1 + 0.5 \times 10^{-t+1})\,|P|[
$$
```{r}
#| code-fold: true
t <- 3 #<1>

intervalo <- function(P, t) { #<2>
  margen <- 0.5 * 10^(-t + 1)
  inferior <- P * (1 - margen)
  superior <- P * (1 + margen)
  data.frame(
    P = P,
    t = t,
    Limite_Inferior = round(inferior, 4),
    Limite_Superior = round(superior, 4)
  )
}

tabla_intervalos <- rbind( #<3>
  intervalo(150, t),
  intervalo(900, t),
  intervalo(1500, t),
  intervalo(90, t)
)

kableExtra::kable(tabla_intervalos) #<4>
```
1. Definir el valor de t
2. Función que devuelve los extremos del intervalo como fila de una tabla
3. Crear tabla con los resultados para varios valores de P
4. Mostrar la tabla (Quarto renderiza automáticamente como tabla bonita)


# Ejercicio 2
::: {.callout-note}
## Instrucción

Considere los siguientes valores para $p$ y $p^*$:

a. $\quad p = \pi\qquad p^* = 3.1$  
b. $\quad p = \tfrac{1}{3}\qquad p^* = 0.333$  
c. $\quad p = \tfrac{\pi}{1000}\qquad p^* = 0.0031$  
d. $\quad p = \tfrac{100}{3}\qquad p^* = 33.3$  

¿Cuál es el error absoluto y relativo al aproximar $p$ por $p^*$?

:::

## Solución

a) 

```{r}
#| code-fold: true
err.abs.a <- abs(pi - 3.1)
err.rel.a <- err.abs.a / pi
```
```{r}
#| echo: false
cat("error absoluto:", err.abs.a)
cat("error relativo:", err.rel.a)
```
b)
```{r}
#| code-fold: true
err.abs.b <- abs(pi/1000 - 0.0031)
err.rel.b <- err.abs.b/(pi/1000)
```
```{r}
#| echo: false
cat("error absoluto:", format(err.abs.b, scientific = F))
cat("error relativo:", err.rel.b)
```

c)
```{r}
#| code-fold: true
err.abs.c <- abs(1/3 - 0.333)
err.rel.c <- err.abs.c/(1/3)
```
```{r}
#| echo: false
cat("error absoluto:", err.abs.c)
cat("error relativo:", err.rel.c)
```
d)
```{r}
#| code-fold: true
err.abs.d <- abs(100/3 - 33.3)
err.rel.d <- err.abs.d/(100/3)
```
```{r}
#| echo: false
cat("error absoluto:", err.abs.d)
cat("error relativo:", err.rel.d)
```

# Ejercicio 3
::: {.callout-note}
## Instrucción

Sea 
$$
\alpha_n = \frac{n+10}{n^5},
$$
pruebe que
$$
A_n = 0+\mathcal{O}\left(\dfrac{1}{n^4}\right)
$$

¿Qué se puede concluir?

:::

## Solución

::: {.callout-caution collapse="true"}
##### Prueba

Sea $\alpha_n = \dfrac{n + 10}{n^5}$ y $\beta_n = \dfrac{1}{n^4}$, y note que para $\alpha = 0$:

\begin{align*}
\left| \frac{\alpha_n - \alpha}{\beta_n} \right| 
&= \left| \frac{\dfrac{n + 10}{n^5} - 0}{\dfrac{1}{n^4}} \right| \\
&= \left| \frac{n^5 + 10n^4}{n^5} \right| 
= \left| 1 + \frac{10}{n} \right| \leq 11 \quad \text{para } n \to \infty
\end{align*}

Así,

$$
\frac{n + 10}{n^5} \in \mathcal{O}\left(\frac{1}{n^4}\right)
$$

es decir, $\dfrac{n + 10}{n^5}$ converge a $0$ tan rápido como $\dfrac{1}{n^4}$ converge a $0$. $\blacksquare$

:::


# Ejercicio 4
::: {.callout-note}
## Instrucción

Suponga que ${fl}(x)$ es una aproximación de $x$ con redondeo a $k$ dígitos.  
Demuestre que:

$$
\left| \frac{x - {fl}(x)}{x} \right| \leq 0.5 \times 10^{-k+1}.
$$

:::

## Solución

Ya que ${fl}(x)$ es una aproximación de $x$ con redondeo a $k$ dígitos eso significa que podemos escribir ${fl}(x)$ de la siguiente forma

$${fl}(x) = 0.d_1 d_2 \cdots d_k \times 10^{n}$$

Sea $x\in\mathbb{R}$ que escribiremos como 

$$x=0.d_1 d_2 \cdots \times 10^{n}$$

De esta forma

\begin{align*}
\left| \frac{x - fl(x)}{x} \right|
&= \left| \frac{0.d_1 d_2 \cdots \times 10^n - 0.d_1 d_2 \cdots d_k \times 10^n}{0.d_1 d_2 \cdots \times 10^n} \right| \\[1ex]
&= \left| \frac{0.d_{k+1} d_{k+2} \cdots \times 10^{n-k}}{0.d_1 d_2 \cdots \times 10^n} \right| \\[1ex]
&= \left| \frac{0.d_{k+1} d_{k+2} \cdots}{0.d_1 d_2 \cdots} \right| \times 10^{-k} \\[1ex]
\end{align*}

Aquí hay que analizar por casos:

- Suponga que $d_{k+1} < 5$

En este caso basta con cortar en $d_k$ así:

\begin{align*}
\left| \frac{x - fl(x)}{x} \right|
&= \left| \frac{0.d_{k+1} d_{k+2} \cdots}{0.d_1 d_2 \cdots} \right| \times 10^{-k} \\[1ex]
&\leq 0.5\cdot\left| \frac{1}{0.1} \right| \times 10^{-k} \\[1ex]
&= 0.5\times 10^{-k+1}
\end{align*}

- Suponga que $d_{k+1} \ge 5$.

Recuerde que para este caso en ${fl}(x)$ pasa que $d_k$ es una unidad mayor que el $d_k$ de $x$. De esta forma se va a cumplir que $d_{j_\text{real}}$$=d_{j_\text{aproximado}}$ para $j=\{1,2,\ldots,k-1\}$ así se tiene que 

$$
|x - fl(x)| = 10^{1-k}\cdot(1-0.d_{k+1}\cdots)
$$
$$
\left| \frac{x - fl(x)}{x} \right| = \frac{10^{1-k}\cdot(1-0.d_{k+1}\cdots)}{|0.d_1 d_2 \cdots\times 10^{n}|}
$$
Vea que 
\begin{align*}
d_{k+1} \ge 5 &\implies 0.d_{k+1}\cdots\ge\frac{1}{2}\\
&\implies 1-0.d_{k+1}\cdots\le\frac{1}{2}\\
&\implies 1-0.d_{k+1}\cdots\le\frac{1}{2}
\end{align*}
Así
$$
\left| \frac{x - fl(x)}{x} \right| \le \frac{10^{1-k} \cdot 0.5}{|0.d_1 d_2 \cdots\times 10^{n}|} \le 10^{1-k} \cdot 0.5
$$
Luego, concluya que 
$$
\left| \frac{x - {fl}(x)}{x} \right| \leq 0.5 \times 10^{-k+1} \qquad \blacksquare
$$

# Ejercicio 5
::: {.callout-note}
## Instrucción

Si se calcula la raíz menor en valor absoluto de la ecuación:

$$
f(x) = x^2 + 0.4002 \times 10^0 x + 0.8 \times 10^{-4} = 0,
$$

con la fórmula cuadrática usual, entonces se produce una pérdida de dígitos significativos.  

¿Por qué?  

Encuentre una fórmula alternativa para efectuar este cálculo sin que se produzca tal pérdida y determine la raíz de menor magnitud.

:::

## Solución

Con la formula usual:
```{r}
a <- 1
b <- 0.4002
c <- 0.8e-4
discriminante <- b^2 -4*a*c
raiz.menor <- abs((-b + sqrt(discriminante))/2*a)
raiz.discriminante <- sqrt(discriminante)

format(raiz.menor, scientific = FALSE, digits = 22)
b
raiz.discriminante
```

Una de las razones por las que hay perdida significativa de digitos es porque al aplicar la raiz del discriminante se obtiene un numero muy parecido a -b, de manera que se esta restando en el numerador numeros muy parecidos.

Una forma de calcular la raiz menor de forma mas precisa es usando la siguiente formula (la cual se obtiene al multiplicar por el conjugado del numerador en forma de un 1 conveniente y desarrollando):

```{r}
raiz.menor.nueva <- abs((2 * c) / (-b - sqrt(discriminante)))
format(raiz.menor.nueva, scientific = FALSE, digits = 22)
```

Con el primer método, se obtiene este error:
```{r}
abs((raiz.menor - 0.0002)/0.0002)
```
Mientras que con el segundo método, el error es mucho menor (en nuestra máquina da que es 0):
```{r}
format(abs((raiz.menor.nueva-0.0002)/0.0002), digits = 22)
```



# Ejercicio 6
::: {.callout-note}
## Instrucción

Escriba una función en R que verifique, para cualquier $n$, la siguiente identidad:

$$
\begin{vmatrix}
x & a_1 & a_2 & \cdots & a_n \\
a_1 & x & a_2 & \cdots & a_n \\
a_1 & a_2 & x & \cdots & a_n \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_1 & a_2 & a_3 & \cdots & x
\end{vmatrix}
=
(x + a_1 + \cdots + a_n)(x-a_1)(x-a_2)\cdots(x-a_n).
$$


:::

## Solución

```{r}
a <- matrix(c(1, 2, 3, 2, 1, 3, 2, 3, 1), byrow = TRUE, nrow = 3)
verificar.identidad <- function(matriz) {
  derecha <- sum(matriz[1, ]) * prod(sapply(matriz[1, ][-1], function(y) {
    return(matriz[1] - y)
  }))
  izquierda <- det(matriz)
  return(
    list(
      "Matriz" = matriz,
      "Determinante" = izquierda,
      "ResultadoFormula" = derecha,
      "SeVerificaIdentidad" = (izquierda == derecha)
    )
  )
}
verificar.identidad(a)
```

# Ejercicio 7
::: {.callout-note}
## Instrucción

Escriba una función en R que verifique para cualquier $n$ la siguiente identidad:

$$
\begin{vmatrix}
1 & 1 & 1 & \cdots & 1 & 1 \\
b_1 & a_1 & a_1 & \cdots & a_1 & a_1 \\
b_1 & b_2 & a_2 & \cdots & a_2 & a_2 \\
\vdots & \vdots & \vdots & \ddots & \ddots & \vdots \\
b_1 & b_2 & b_3 & \cdots & b_n & a_n
\end{vmatrix}
=
(a_1 - b_1)(a_2 - b_2)\cdots(a_n - b_n).
$$

:::

## Solución

```{r}
identidad <- function(df) {
  n <- ncol(df) - 1
  # Validaciones básicas
  if (nrow(df) != n + 1) return(FALSE)
  if (!all(df[1, ] == 1)) return(FALSE)
  M <- df[-1, ] #<1>
  a <- diag(M[, -1])
  b <- diag(M[, -ncol(M)])
  
  estructura_valida <- all( #<2>
    sapply(1:n, function(i) {
      fila <- M[i, ]
      izquierda <- fila[1:i]
      derecha <- fila[(i+1):(n+1)]
      all(izquierda == b[i]) && all(derecha == a[i])
    })
  )
  if (!estructura_valida) return(FALSE)
  return(isTRUE(all.equal(det(df), prod(a - b)))) #<3> 
}

```
1. Extraer submatriz sin la primera fila
2. Verificar estructura: por filas, los valores deben seguir patrón
3. Validar identidad con tolerancia numérica


### Prueba
```{r}
df <- matrix(c(
  1, 1, 1, 1,
  2, 3, 3, 3,
  2, 2, 4, 4,
  2, 2, 2, 5
), nrow = 4, byrow = TRUE)

identidad(df)
```



---

# Ejercicio 8
::: {.callout-note}
## Instrucción

Se dice que una matriz es *rala* si esta tiene más entradas nulas que no nulas (mayor estricto).  
Escriba una función en R que permita determinar si una matriz es rala.

:::

## Solución

```{r}
a <- matrix(c(0, 0, 0, 0, 0, 3, 2, 4, 5), nrow = 3, byrow = TRUE)
es.rala <- function(matriz) {
  nulos <- sum(sapply(matriz, function(y) {
    if (y == 0) {
      return(1)
    }
    else {
      return(0)
    }
  }))
  no.nulos <- length(matriz) - nulos
  
  return(list("Matriz" = matriz, "entradas nulas" = nulos, "entradas no nulas" = no.nulos, "EsRala" = nulos > no.nulos))
}
es.rala(a)

```
---

# Ejercicio 9
::: {.callout-note}
## Instrucción

Se dice que una matriz $A \in M_{n \times m}$ tiene *forma de O* si todas las entradas de la fila 1, fila $n$, columna 1 y columna $m$ no son nulas, y las demás entradas de la matriz son nulas.  
Escriba una función en R que permita determinar si una matriz está en forma de O.

:::

## Solución

```{r}
a <- matrix(c(1, 1, 1, 1, 0, 1, 1, 1, 1), nrow = 3, byrow = TRUE)
es.o <- function(matriz) {
  fila.1 <- matriz[1, ]
  fila.n <- matriz[nrow(matriz), ]
  col.1 <- matriz[, 1]
  col.n <- matriz[, ncol(matriz)]
  
  if (nrow(matriz) > 2 && ncol(matriz) > 2) {
    matriz.central <- matriz[-c(1, nrow(matriz)), -c(1, ncol(matriz)), drop = FALSE]
  } else {
    matriz.central <- NULL
  }
  
  todo.bien <- TRUE
  
  for (elem in seq_along(fila.1)) {
    if (fila.1[elem] == 0 || fila.n[elem] == 0) {
      todo.bien <- FALSE
      break
    }
  }
  
  if (todo.bien) {
    for (elem in seq_along(col.1)) {
      if (col.1[elem] == 0 || col.n[elem] == 0) {
        todo.bien <- FALSE
        break
      }
    }
  }
  
  if (todo.bien && !is.null(matriz.central)) {
    for (elem in matriz.central) {
      if (elem != 0) {
        todo.bien <- FALSE
        break
      }
    }
  }
  
  return(list("Matriz" = matriz, "Tiene forma de O" = todo.bien))
}

es.o(a)
```
---

# Ejercicio 10
::: {.callout-note}
## Instrucción

En el capítulo de análisis funcional complete las demostraciones de los teoremas 2, 4, 5, 14, 16 y de los ejemplos 3, 5.

:::

## Solución

::: {.callout-tip}
## Teorema 2
En un espacio vectorial de dimensión finita todas las normas son equivalentes.  

::: {.callout-caution collapse="true"}
### Prueba


Vamos a proceder a probar que **todas las normas son equivalentes a $\|\cdot\|_2$**, la norma euclideana.  
Recordemos que:

$$
\|x\|_2 = \left( \sum_{i=1}^n |x_i|^2 \right)^{1/2}
$$

Sea $\|\cdot\|$ una norma cualquiera en $X$, y consideremos el conjunto:

$$
S = \{x \in X : \|x\|_2 = 1\}
$$

Es decir, **la esfera unitaria respecto a $\|\cdot\|_2$**.

Este conjunto $S$ es **cerrado y acotado** $\Rightarrow$ es **compacto** (por el teorema de Heine-Borel en dimensión finita).

La función $f(x) = \|x\|$ es continua en $S$, por lo que alcanza su mínimo $m > 0$ y su máximo $M > 0$.

Así, para todo $x \in X$:

$$
m \leq \|x\| \leq M \quad \text{para } x \in S
$$

---

Ahora, sea $x \in X \setminus \{0\}$. Note que:

\begin{align*}
\|x\| &= \left\| \|x\|_2 \cdot \frac{x}{\|x\|_2} \right\| 
= \|x\|_2 \cdot \left\| \frac{x}{\|x\|_2} \right\|
\end{align*}

Vea que $\frac{x}{\|x\|_2} \in S$ (pues su norma euclideana es 1).  
Por lo tanto, aplicando la cota sobre $S$:

\begin{align*}
m \cdot \|x\|_2 \leq \|x\| \leq M \cdot \|x\|_2
\end{align*}

Esto prueba que las normas $\|\cdot\|$ y $\|\cdot\|_2$ son **equivalentes**.

Como la norma $\|\cdot\|$ era arbitraria, concluimos que **todas las normas** en $X$ son equivalentes.


$\blacksquare$
:::
:::

---

::: {.callout-tip}
## Teorema 4
Para todo producto interno se tiene la desigualdad de Cauchy–Schwarz:

$$|\langle x, y \rangle|^2 \leq \langle x, x \rangle \langle y, y \rangle,$$

para todo $x, y \in X$, además se tiene igualdad si para todo $x, y$ son linealmente dependientes.  

::: {.callout-caution collapse="true"}
### Prueba

Si $x = 0$ la desigualdad es trivial. Si $x \neq 0$, tome  

$$z = y - \frac{\langle y, x \rangle}{\|x\|^2} x,$$

luego es claro que $\langle z, x \rangle = 0$ y que:

$$
0 \leq \|z\|^2 
= \left\langle y - \frac{\langle y, x \rangle}{\|x\|^2}x , \, y - \frac{\langle y, x \rangle}{\|x\|^2}x \right\rangle
= \langle y, y \rangle - \frac{\langle y, x \rangle \langle x, y \rangle}{\|x\|^2}
= \|y\|^2 - \frac{|\langle x, y \rangle|^2}{\|x\|^2}.
$$


por lo tanto:

$$
|\langle x, y \rangle|^2 \leq \|x\|^2 \|y\|^2 = \langle x, x \rangle \langle y, y \rangle.
$$

Para la igualdad, observe que $\|z\|^2 = 0$ si y solo si $z = 0$, es decir:

$$
y = \frac{\langle y, x \rangle}{\|x\|^2} x = \lambda x,
$$

para $\lambda \in \mathbb{R}$ (o $\mathbb{C}$). Por lo tanto, $x$ y $y$ son linealmente dependientes.

Recíprocamente, si $y = \lambda x$, entonces:

$$
\langle x, y \rangle = \langle x, \lambda x \rangle = \lambda \langle x, x \rangle,
$$

y por lo tanto:

$$
|\langle x, y \rangle|^2 = |\lambda|^2 \langle x, x \rangle^2 = \langle x, x \rangle (\lambda \overline{\lambda} \langle x, x \rangle) = \langle x, x \rangle \langle y, y \rangle.
$$

Así, se tiene igualdad si y solo si $x$ y $y$ son linealmente dependientes.


$\blacksquare$
:::
:::

---

::: {.callout-tip}
## Teorema 5
Sea $X$ un espacio vectorial complejo (o real). Entonces la función  

$$
\|x\| := \langle x, x \rangle^{1/2}
$$

define una norma en $X$, es decir un espacio pre–Hilbert es siempre un espacio normado.  

::: {.callout-caution collapse="true"}
### Prueba

Sea $X$ un espacio pre–Hilbert, defina la función $\langle \cdot,\cdot \rangle : X \times X \to \mathbb{C}$ (o $\mathbb{R}$) y vea que para $x\in V$

 - $\langle x, x \rangle \geq 0 \implies \langle x, x \rangle^{1/2}\ge 0$
 - $\Big(\langle x, x \rangle = 0 \iff x = 0 \Big)\implies\Big( \langle x, x \rangle^{1/2} = 0 \iff x = 0 \Big)$
 - Sea $\alpha\in\mathbb{C}$ (o $\mathbb{R}$) entonces
 
 \begin{align*}
 \langle \alpha x, \alpha x \rangle^{1/2} &= \Big( \alpha\langle x, \alpha x \rangle\Big)^{1/2}\\
 &= \Big( \alpha\overline{\langle \alpha x, x \rangle}\Big)^{1/2}\\
  &= \Big( \alpha\cdot\overline{\alpha} \cdot {\langle x, x \rangle}\Big)^{1/2}\\
  &= \Big( |\alpha|^2 {\langle x, x \rangle}\Big)^{1/2}\\
 &=  |\alpha|\langle x, x \rangle^{1/2}\\
 \end{align*}
 
 - Sea $y \in V$ entonces
 
 \begin{align*}
  \langle x+y, x+y \rangle^{1/2} &= \Big(\langle x, x+y \rangle + \langle y, x+y \rangle\Big)^{1/2} \\
  &= \Big(\overline{\langle x+y, x \rangle} + \overline{\langle x+y, y \rangle}\Big)^{1/2} \\
&= \Big( \langle x,x \rangle + \langle x,y \rangle + \langle y,x \rangle + \langle y,y \rangle \Big)^{1/2}\\
&\le \Big( \langle x,x \rangle + 2\cdot \langle x, x \rangle^{1/2} \langle y, y \rangle^{1/2} + \langle y,y \rangle \Big)^{1/2}\\
\end{align*}

Esto último asumiendo que $\langle y,x \rangle = \overline{\langle y,x \rangle}$ y usando Cauchy–Schwarz. De esta forma vea que 

\begin{align*}
\langle x+y, x+y \rangle &\le \langle x,x \rangle + 2\cdot \langle x, x \rangle^{1/2} \langle y, y \rangle^{1/2} + \langle y,y \rangle\\[1ex]
&= \Big( \langle x, x \rangle^{1/2} + \langle y, y \rangle^{1/2}\Big)^{2}\\[1ex]
\implies \qquad \langle x+y, x+y \rangle^{1/2} &\le  \langle x, x \rangle^{1/2} + \langle y, y \rangle^{1/2}
\end{align*}

Vea que la función $\|\cdot\| := \langle \cdot, \cdot \rangle^{1/2}$ cumple las propiedades de una norma, por lo que $\|\cdot\|$ sería la norma del espacio de pre-Hilbert $X$. Así se puede concluir que el espacio pre–Hilbert es siempre un espacio normado $\qquad\blacksquare$


:::
:::

---

::: {.callout-tip}
## Teorema 14
Sea $U$ un subespacio vectorial de un espacio de pre–Hilbert $X$.  
Un elemento $v$ es la mejor aproximación a $w \in X$ con respecto a $U$ si y solo si:

$$
\langle w - v, u \rangle = 0 \quad \forall u \in U.
$$

Es decir, si y solamente si $w - v \perp U$. Además, para cada $w \in X$ existe a lo más una única mejor aproximación con respecto a $U$.

::: {.callout-caution collapse="true"}
### Prueba


**$(\Rightarrow)$** Sea $r := w - v$, para cualquier $u \in U$ y todo $t \in \mathbb{R}$.  
Note que $v + t u \in U$.

Como $v$ es la mejor aproximación:

\begin{align*}
\|w - (v + tu)\|^2 &\geq \|w - v\|^2 \quad \forall t \in \mathbb{R} \\
\|r - tu\|^2 &= \|r\|^2 - 2t \operatorname{Re} \langle r, u \rangle + t^2 \|u\|^2 \geq \|r\|^2 \quad \forall t \in \mathbb{R}
\end{align*}

Entonces:

\begin{align*}
-2t \operatorname{Re} \langle r, u \rangle + t^2 \|u\|^2 \geq 0 \quad \forall t \in \mathbb{R}
\end{align*}

La única forma en que esto ocurre para todo $t$ es que $\langle r, u \rangle = 0$,  
por tanto:

$$
\langle w - v, u \rangle = 0
$$


**$(\Leftarrow)$**  Sea $r := w - v$ y tome cualquier $u \in U$.

Si $v - u \in U$ y $\langle w - v, u \rangle = 0$, entonces:

\begin{align*}
\|w - u\|^2 &= \|(w - v) + (v - u)\|^2 \\
&= \|r\|^2 + \|v - u\|^2 + 2 \operatorname{Re} \langle r, v - u \rangle \\
&= \|r\|^2 + \|v - u\|^2 \geq \|r\|^2 \quad \text{(ya que $\langle r, v - u \rangle = 0$)}
\end{align*}

Por lo tanto, $v$ es la mejor aproximación de $w$ en $U$.

**Unicidad:**

Si $v, v' \in U$ fuesen dos mejores aproximaciones, entonces:

\begin{align*}
\|w - v\|^2 &= \|w - v'\|^2 \\
\text{y } \quad \|w - v\|^2 &= \|w - v'\|^2 + \|v - v'\|^2
\end{align*}

Esto implica que:

$$
\|v - v'\|^2 = 0 \Rightarrow v' = v
$$

$\blacksquare$
:::
:::

---

::: {.callout-tip}
## Teorema 16
Sea $U$ un subespacio vectorial completo de un espacio pre–Hilbert $X$.  
Entonces para cada elemento $w \in X$ existe una única mejor aproximación con respecto a $U$.

- El operador $P : X \to U$ que le asigna a $w \in X$ su mejor aproximación es un operador lineal acotado con las siguientes propiedades:

$$
P^2 = P \quad \text{y} \quad \|P\| = 1.
$$

- Este operador se conoce como la **proyección ortogonal** de $X$ sobre $U$.

::: {.callout-caution collapse="true"}
### Prueba

Sea $U \subseteq X$ un subespacio cerrado y convexo de un espacio de Hilbert completo $X$.

- Por el **Teorema 14**, sabemos que para cada $w \in X$ existe una mejor aproximación respecto a $U$, y además esta es única.

- Sea $P : X \to U$ el operador que asigna la mejor aproximación respecto a $U$.

Es claro que el operador es acotado, pues para todo $w \in X$ se cumple:

$$
P_w \leq \hat{u}
$$

donde $\hat{u} \in U$ cumple que $\|w - \hat{u}\| = \sup_{u \in U} \|w - u\|$.  
Es decir, la "peor aproximación" de $w$ respecto a $U$.

Suponga que $v \in U$ es la mejor aproximación de $w \in X$, es decir, $P_w = v$.  
Note que $v$ es la mejor aproximación de sí mismo, ya que:

\begin{align*}
0 \leq \inf_{u \in U} \|v - u\| \leq \|v - v\| = 0 \\
\Rightarrow \inf_{u \in U} \|v - u\| = 0 \Rightarrow P_v = v
\end{align*}

Entonces, vea que:

$$
P^2 w = P(Pw) = P(v) = v = Pw
$$

Con esto se concluye que $P^2 = P$. 
$\blacksquare$
:::
:::

---

::: {.callout-tip}
## Ejemplo 3
El espacio vectorial $C[a,b]$ provisto con la norma  

$$
\|f\|_\infty := \max_{x \in [a,b]} |f(x)|
$$  

es un espacio de Banach.  

::: {.callout-caution collapse="true"}
### Prueba


Sea $\{x_n\}$ una sucesión de Cauchy en $C([a,b])$.

Sea $\varepsilon > 0$.  
Dado que $\{x_n\}$ es de Cauchy, existe $n_0 \in \mathbb{N}$ tal que:

$$
\|x_n - x_m\|_\infty < \varepsilon \quad \forall n, m \geq n_0
$$

Entonces:

$$
\sup_{t \in [a,b]} |x_n(t) - x_m(t)| < \varepsilon \quad \Rightarrow \quad |x_n(t) - x_m(t)| < \varepsilon \quad \forall t \in [a,b], \, n, m \geq n_0
$$

Para cada $t \in [a,b]$, la sucesión $\{x_n(t)\}_{n=1}^\infty$ es de Cauchy en $\mathbb{R}$.  
Como $\mathbb{R}$ es completo, existe un límite:

$$
\lim_{n \to \infty} x_n(t) = x(t) \in \mathbb{R}, \quad \forall t \in [a,b]
$$

Por tanto, $x$ es una función de $[a,b]$ en $\mathbb{R}$ y definimos $x \in C([a,b])$.


Sea $t_0 \in [a,b]$.  
Notamos que:

\begin{align*}
|x(t) - x(t_0)| &\leq |x(t) - x_{n_0}(t)| + |x_{n_0}(t) - x_{n_0}(t_0)| + |x_{n_0}(t_0) - x(t_0)| \\
&< \varepsilon + \varepsilon + \varepsilon = 3\varepsilon
\end{align*}

Ya que $x_{n_0} \in C([a,b])$, es continua en $t_0$, entonces existe $\delta > 0$ tal que:

$$
|x_{n_0}(t) - x_{n_0}(t_0)| < \varepsilon \quad \text{si } |t - t_0| < \delta
$$

Y como además $|x(t) - x_{n_0}(t)| < \varepsilon$ y $|x_{n_0}(t_0) - x(t_0)| < \varepsilon$, se concluye que $x \in C([a,b])$.

Finalmente, dado que:

$$
\sup_{t \in [a,b]} |x_n(t) - x(t)| < \varepsilon \quad \Rightarrow \quad \|x_n - x\|_\infty < \varepsilon \quad \forall n \geq n_0
$$

tenemos que $x_n \to x$ en la norma $\|\cdot\|_\infty$.

Por tanto:

$$
C([a,b]), \; \|\cdot\|_\infty \text{ es un espacio de Banach.}
$$


$\blacksquare$
:::
:::

---

::: {.callout-tip}
## Ejemplo 5
El espacio vectorial $C[a,b]$ provisto con la norma $L_2$:

$$
\|f\|_1 := \left( \int_a^b |f(x)|^2 dx \right)^2
$$  

NO es un espacio de Banach.  

::: {.callout-caution collapse="true"}
### Prueba 

Hay que probar que el espacio vectorial $C[a,b]$ normado provisto con la norma $L_2$ **NO** es completo. Es decir,
hay que encontrar una sucesión de Cauchy de elementos de $U$ que **NO** converge a un elemento en $U$, siendo $U$ un subconjunto del espacio vectorial $C[a,b]$

Sin pérdida de generalidad se toma $[a,b] = [0,2]$ y se escoge:

$$
f_n(x) := 
\begin{cases}
x^n & \text{si } 0 \leq x \leq 1, \\
1   & \text{si } 1 < x \leq 2.
\end{cases}
$$

Para todo $m > n$ se tiene que:

\begin{align*}
\| f_n - f_m \|_1
&= \left( \int_0^2 |f_n(x) - f_m(x)|^2 \, dx \right)^2\\[1ex]
&= \left( \int_0^1 |x^n - x^m|^2 \, dx \right)^2\\[1ex]
&= \left( \int_0^1 \big(x^{2n} - 2x^{n+m} + x^{2m}\big) \, dx \right)^2\\[1ex]
&= \left( \frac{1}{2n+1} - \frac{2}{n+m+1} + \frac{1}{2m+1} \right)^2 \to 0
\quad \text{cuando } n,m \to \infty,
\end{align*}

por lo tanto $(f_n)$ es una sucesión de Cauchy. 

Ahora, supongamos que la sucesión $(f_n)$ converge a una función continua $f$ con respecto a la norma $L_1$, es decir:

$$
\| f_n - f \|_1 \to 0 \quad \text{cuando } n \to \infty.
$$
Entonces,

\begin{align*}
\|f\|_{1} 
  &= \|(f-x^{n})+x^{n}\|_{1}
\\
  &\le \|f-x^{n}\|_{1} + \|x^{n}\|_{1}
  \qquad\text{(desigualdad triangular)}
\\
  &= \|f-f_{n}\|_{1} + \left(\int_{0}^{1} |x^{n}|^{2}\,dx\right)^{2}
\\
  &= \|f-f_{n}\|_{1} + \left(\int_{0}^{1} x^{2n}\,dx\right)^{2}
\\
  &= \|f-f_{n}\|_{1} + \left(\frac{1}{2n+1}\right)^{2}
  \xrightarrow[n\to\infty]{} 0
\end{align*}
de donde $f(x) = 0$ para $0 \leq x \leq 1$.

Vea además que 

\begin{align*}
\Biggl(\int_{1}^{2}\!\bigl|f(x)-1\bigr|^{2}\,dx\Biggr)^{2} 
&= \Biggl(\int_{1}^{2}\!\bigl|f(x)-f_n(x)\bigr|^{2}\,dx\Biggr)^{2} 
\qquad\text{(pues $f_n(x)=1$ en $(1,2]$)}\\[4pt]
&\le \Biggl(\int_{0}^{2}\!\bigl|f(x)-f_n(x)\bigr|^{2}\,dx\Biggr)^{2} 
= \,\|f-f_n\|_{1}\;\xrightarrow[n\to\infty]{}\;0 .
\end{align*}

esto implica que $f(x) = 1$ para $1 \leq x \leq 2$.  
Por lo tanto $f$ no es continua, lo cual es una contradicción. $\qquad\blacksquare$
:::
:::

---

# Ejercicio 11
::: {.callout-note}
## Instrucción

En el teorema 7, si tomamos como espacio pre–Hilbert a $\mathbb{R}^n$ con el producto punto clásico, escriba una función en R que reciba una base de un subespacio de $\mathbb{R}^n$ en una lista de listas y retorne la base ortogonal en una lista de listas, luego otra función que calcule la base ortonormal.

:::

## Solución

```{r}
prod.punto <- function(x, y) {
  return(sum(x * y))
}

norma <- function(x) {
  return(sqrt(prod.punto(x, x)))
}

proy.ortogonal <- function(u, v) {
  (prod.punto(u, v) / prod.punto(v, v)) * v
}

gs.ortogonal <- function(base) {
  U <- base
  Q <- list()
  for (k in seq_along(U)) {
    u <- U[[k]]
    if (length(Q) > 0) {
      for (q in Q)
        u <- u - proy.ortogonal(u, q)
    }
    Q[[length(Q) + 1]] <- u
  }
  return(Q)
}

gs.ortonormal <- function(base) {
  base.ortogonal <- gs.ortogonal(base)
  return(lapply(base.ortogonal, function(x) {
    return(x / norma(x))
  }))
}

base <- list(c(1,2,3), c(4,5,6), c(1,0,1))
gs.ortogonal(base)
gs.ortonormal(base)
```




---

# Ejercicio 12
::: {.callout-note}
## Instrucción

Repita el ejercicio anterior usando los espacios y el producto interno del ejemplo 7.  
¿Será posible hacer una función que reciba también como parámetro el producto interno como una función de $\mathbb{R}^n \times \mathbb{R}^n$ en $\mathbb{R}$ y genere la base ortogonal y ortonormal usando este producto interno?

:::

## Solución

```{r}

resta  <- function(f, g) { force(f); force(g); function(x) f(x) - g(x) }
suma   <- function(f, g) { force(f); force(g); function(x) f(x) + g(x) }
escala <- function(a, f) { force(a); force(f); function(x) a * f(x) }


prod.l2 <- function(f, g) {
  integrate(function(x) f(x) * g(x), lower = 0, upper = 1)$value
}

norma.l2 <- function(x, prod.interno) {
  return(sqrt(prod.interno(x, x)))
}

proy.ortogonal.l2 <- function(u, v, prod.interno) {
  num <- prod.interno(u, v)
  den <- prod.interno(v, v)
  cte <- num / den
  return(escala(cte, v))
}

gs.ortogonal.l2 <- function(base, prod.interno) {
  Q <- list()
  for (k in seq_along(base)) {
    u <- base[[k]]
    if (length(Q) > 0) {
      for (q in Q) {
        u <- resta(u, proy.ortogonal.l2(u, q, prod.interno))
      }
    }
    Q[[length(Q) + 1]] <- u
  }
  return(Q)
}

normalizar <- function(base, prod.interno) {
  Q <- list()
  for (k in seq_along(base)) {
    u <- base[[k]]
    nrm <- norma.l2(u, prod.interno)
    u.nrm <- escala(1/nrm, u)
    Q[[length(Q) + 1]] <- u.nrm
  }
  return(Q)
}

# Ejemplo de prueba

f1 <- function(x) x*0 + 1
f2 <- function(x) x
f3 <- function(x) x^2
base <- list(f1, f2, f3)

#Se obtiene la base ortonormal
base.ortonormal <- normalizar(gs.ortogonal.l2(base, prod.l2), prod.l2)

```
Para verificar que la base que se obtuvo es en efecto ortonormal (puesto que no se puede ver de fondo cuales son las funciones), se emplea esta funcion, en donde se crea una matriz con los productos internos entre todos los elementos de la base entre si. En la diagonal, vemos que el producto l2 entre dos elementos iguales es 1, lo que evidencia que todos los "vectores" tienen norma 1. Por otra parte, vemos que todos los productos entre elementos diferentes da 0, lo que evidencia que son ortogonales:

```{r}
G <- sapply(seq_along(base.ortonormal), function(i)
  sapply(seq_along(base.ortonormal), function(j) prod.l2(base.ortonormal[[i]], base.ortonormal[[j]])))
round(G, 6)  
```
Con respecto a si se puede hacer una funcion "general" en donde uno le introduzca como parametro el producto interno, la respuesta es que sí se podria. El método de Gram–Schmidt en realidad solo ocupa que uno pueda calcular el producto interno entre los elementos de la base. Entonces, si yo le paso como parámetro cualquier producto interno válido, ya sea el usual o uno definido de otra forma, el proceso se puede aplicar igual y genera la base ortogonal y luego la ortonormal usando esa “regla” de producto interno.


---

# Ejercicio 13
::: {.callout-note}
## Instrucción

::: {.callout-note}
##### Corolario 2

Sea $U$ un subespacio vectorial de dimensión finita de un espacio pre-Hilbert $X$ con base ortonormal $u_{1}, u_{2}, \dots, u_{n}$.  
Entonces la proyección ortogonal está dada por:  

$$
Pw = \sum_{k=1}^{n} \langle w, u_{k} \rangle u_{k}, \quad \text{con } w \in X.
$$
:::

En el Corolario 2, si tomamos como espacio pre–Hilbert a $\mathbb{R}^n$ con el producto punto clásico, escriba una función en R que reciba una base de un subespacio $U$ de $\mathbb{R}^n$ en una lista de listas, un vector de $\mathbb{R}^n$ y retorne en una lista la mejor aproximación a ese vector en $U$.

:::

## Solución

```{r}
prod.punto <- function(x, y) {
  return(sum(x * y))
}

mejor.aprox <- function(base, vector) {
  U <- gs.ortonormal(base)
  aprox <- numeric(length(vector))
  coef  <- numeric(length(U))
  
  for (k in seq_along(U)) {
    u <- U[[k]]
    coef[k] <- prod.punto(vector, u)
    aprox <- aprox + coef[k] * u
  }
  
  return(list("Aproximacion" = aprox, "Coeficientes" = coef))
}

mejor.aprox(list(c(1,2, 3), c(4, 5, 6)), c(1,0,1))
```




---

# Ejercicio 14
::: {.callout-note}
## Instrucción

Repita el ejercicio anterior usando los espacios y el producto interno del ejemplo 7.  
¿Será posible hacer una función que reciba también como parámetro el producto interno como una función de $\mathbb{R}^n \times \mathbb{R}^n$ en $\mathbb{R}$ y genere la mejor aproximación usando este producto interno?

:::

## Solución

```{r}
#| code-fold: true
prod.l2 <- function(f, g) {
  integrate(function(x) f(x) * g(x), lower = 0, upper = 1)$value
}

mejor.aprox.2 <- function(base, f, prod.interno = prod.l2) {
  coef <- sapply(base, function(u) prod.interno(f, u))
  aprox <- function(x) {
    s <- 0
    for (k in seq_along(base)) {
      s <- s + coef[k] * base[[k]](x)
    } 
    return(s)
  }
  return(list("Aproximacion" = aprox, "Coeficientes" = coef))
}
```
```{r}
#| message: false
#| warning: false
#| code-fold: true
library(tidyverse)
# Base del ejemplo 7
u1 <- function(x) 1
u2 <- function(x) sqrt(3) * (2*x - 1)
u3 <- function(x) sqrt(5) * (6*x^2 - 6*x + 1)
B_ON <- list(u1, u2, u3)

f <- function(x) tan(x)

res <- mejor.aprox.2(B_ON, f)
Pf  <- res$Aproximacion

x  <- seq(0, 1, length.out = 400)
df <- data.frame(x = x, real = f(x), aprox = Pf(x))

ggplot(df, aes(x = x)) +
  geom_line(aes(y = real, color = "f(x) = tan(x)"), size = 1.1) +
  geom_line(aes(y = aprox, color = "Aproximación (P2)"),
            size = 1.1,
            linetype = "dashed") +
  scale_color_manual(values = c(
    "f(x) = tan(x)" = "black",
    "Aproximación (P2)" = "red"
  )) +
  labs(
    title = expression(paste("f(x)=tan(x) vs proyección en ", P[2], "[0,1]")),
    x = "x",
    y = "valor",
    color = "Curva"
  ) +
  theme_minimal(base_size = 12) +
  theme(legend.position = "top")

```


---


# Ejercicio 15
::: {.callout-note}
## Instrucción

Pruebe que la función $f(x) = \sqrt{x+2}$ tiene un punto fijo único en $[0,7]$.

:::

## Solución

::: {.callout-caution collapse="true"}
##### Prueba

Vea que $\mathbb{R}$ es un espacio de Banach bajo la norma valor absoluto.

Vamos a probar que $f(x) \in [0, 7]$ para todo $x \in [0, 7]$. Note que:

$$
f'(x) = \frac{1}{2} \cdot \frac{1}{(x + 2)^{1/2}} \Rightarrow 0 < f'(x) \quad \forall x \in [0, 7]
$$

Por lo tanto, los valores mínimos y máximos de $f$ en $[0, 7]$ se alcanzan en los extremos:

\begin{align*}
f(0) &= \sqrt{2} \approx 1.4142 \\
f(7) &= \sqrt{9} = 3
\end{align*}

Entonces:

$$
0 \leq f(x) \leq 3 \leq 7 \quad \Rightarrow \quad f(x) \in [0,7] \quad \forall x \in [0,7]
$$

Por el **Teorema de punto fijo de Banach**, $f$ tiene **al menos un punto fijo** en $[0,7]$.

---

Para la **unicidad**, calculemos la constante de Lipschitz:

\begin{align*}
L &= \max_{x \in [0,7]} |f'(x)| = |f'(0)| = \frac{1}{2\sqrt{2}} < 1
\end{align*}

Por lo tanto, $f$ es una **contracción** en $[0,7]$, y el Teorema de Banach garantiza la **unicidad** del punto fijo. $\blacksquare$
:::

---


# Ejercicio 16
::: {.callout-note}
## Instrucción

Sea $f : X \to X$ una aplicación. Denotamos por $F_f$ el conjunto de puntos fijos de la aplicación $f$.  
Pruebe las siguientes propiedades:

  a. Sean $f, g : X \to X$ aplicaciones tales que $f \circ g = g \circ f$ entonces se tiene que:
$$
f(F_g) \subset F_g, \quad g(F_f) \subset F_f.
$$

  b. Sean $f, g : X \to X$ aplicaciones, si $F_g = \{x^*\}$ y $f \circ g = g \circ f$ entonces $F_f \neq \varnothing$.

  c. Sea $X \neq \varnothing$ y $f : X \to X$ aplicación. Si existe $n \in \mathbb{R}$ tal que $F_{f^n} = \{x^*\}$ entonces $F_f = \{x^*\}$.

  d. Sea $X \neq \varnothing$ y $f : X \to X$ aplicación. Si $F_f \neq \varnothing$ entonces $F_{f^n} \neq \varnothing$ para todo $n \in \mathbb{N}$.

  e. Sea $X \neq \varnothing$ y $f : X \to X$ aplicación sobreyectiva, supóngase que $f_d^{-1} : X \to X$ es tal que $f \circ f_d^{-1} = I_X$ y $F_{f_d^{-1}} \neq \varnothing$ entonces $F_f \neq \varnothing$.

  f. Sea $A$ un conjunto con un número impar de elementos y $f : A \to A$ tal que $f^2(x) = x$ para todo $x \in A$, se tiene entonces que $F_f \neq \varnothing$.

  g. Sea $f : \mathbb{R} \to \mathbb{R}$ con $f$ continua y acotada entonces $F_f \neq \varnothing$.

  h. Sea $f : \mathbb{R} \to \mathbb{R}$ con $f$ continua y periódica entonces $F_f \neq \varnothing$.

:::

## Solución

  a. Sean $f, g : X \to X$ aplicaciones tales que $f \circ g = g \circ f$ entonces se tiene que:
  $$
  f(F_g) \subset F_g, \quad g(F_f) \subset F_f.
  $$
  
::: {.callout-caution collapse="true"}
### Prueba


Tome $x_i \in F_g$.  
Entonces:

$$
g(x_i) = x_i \quad \Rightarrow \quad f(g(x_i)) = f(x_i)
$$

Pero como $f \circ g = g \circ f$, también se cumple que:

$$
g(f(x_i)) = f(g(x_i)) = f(x_i)
$$

Por lo tanto:

$$
f(x_i) \in F_g \quad \Rightarrow \quad f(F_g) \subseteq F_g
$$

La misma lógica se puede emplear para mostrar que:

$$
g(F_f) \subseteq F_f 
$$

$\blacksquare$
:::

  b. Sean $f, g : X \to X$ aplicaciones, si $F_g = \{x^*\}$ y $f \circ g = g \circ f$ entonces $F_f \neq \varnothing$.
  
::: {.callout-caution collapse="true"}
### Prueba

Sea $F_g = \{x^*\}$, es decir, $x^*$ es el único punto fijo de $g$.  
Entonces:

$$
g(x^*) = x^* \Rightarrow f(g(x^*)) = f(x^*) \Leftrightarrow g(f(x^*)) = f(x^*)
$$

Esto implica que $f(x^*) \in F_g = \{x^*\}$, por lo tanto $f(x^*) = x^*$,  
es decir, $x^*$ también es punto fijo de $f$.

Así que:

$$
\{x^*\} \subseteq F_f \quad \Rightarrow \quad F_f \neq \varnothing
$$


$\blacksquare$
:::

  c. Sea $X \neq \varnothing$ y $f : X \to X$ aplicación. Si existe $n \in \mathbb{R}$ tal que $F_{f^n} = \{x^*\}$ entonces $F_f = \{x^*\}$.
  
::: {.callout-caution collapse="true"}
### Prueba

Sea $f : X \to X$ una aplicación con $X \neq \varnothing$.  
Si existe $n \in \mathbb{N}$ tal que $F_{f^n} = \{x^*\}$, entonces:

$$
F_f = \{x^*\}
$$


Suponga que existe $n \in \mathbb{N}$ tal que $F_{f^n} = \{x^*\}$,  
es decir, $x^*$ es el único punto fijo de $f^n$, es decir:

$$
f^n(x^*) = x^*
$$

Como $f(x^*) \in X$, evaluamos:

\begin{align*}
f^n(f(x^*)) &= f^{n+1}(x^*) = f(f^n(x^*)) = f(x^*)
\end{align*}

Entonces $f(x^*)$ es también punto fijo de $f^n$,  
pero como $F_{f^n} = \{x^*\}$, se deduce que $f(x^*) = x^*$.  
Así, $x^*$ es punto fijo de $f$.

---

Ahora, probemos la **unicidad**. Suponga que existe $\hat{x} \in X$ con $\hat{x} \neq x^*$ tal que $f(\hat{x}) = \hat{x}$.

Entonces aplicando $f$ $n$ veces:

$$
f^n(\hat{x}) = f(f(\dots f(\hat{x}) \dots)) = f(\hat{x}) = \hat{x}
$$

Esto implica que $\hat{x} \in F_{f^n} = \{x^*\}$,  
lo cual contradice que $\hat{x} \neq x^*$.

Por tanto, $x^*$ es el único punto fijo de $f$:

$$
F_f = \{x^*\}
$$

$\blacksquare$
:::

  d. Sea $X \neq \varnothing$ y $f : X \to X$ aplicación. Si $F_f \neq \varnothing$ entonces $F_{f^n} \neq \varnothing$ para todo $n \in \mathbb{N}$.
  
::: {.callout-caution collapse="true"}
### Prueba


Sabemos que:

$$
F_f \neq \varnothing \Rightarrow \exists x \in X \text{ tal que } f(x) = x
$$

**Caso base:** $n = 1$  
Esto es trivial porque $F_{f^1} = F_f \neq \varnothing$ por hipótesis.

**Paso inductivo:** Supongamos que $F_{f^n} \neq \varnothing$,  
es decir:

$$
\exists x \in X \text{ tal que } f^n(x) = x
$$

Entonces:

\begin{align*}
f(f^n(x)) &= f(x) \\
\Rightarrow f^{n+1}(x) &= x
\end{align*}

Por lo tanto:

$$
x \in F_{f^{n+1}} \Rightarrow F_{f^{n+1}} \neq \varnothing
$$

Concluimos por inducción que:

$$
F_{f^n} \neq \varnothing \quad \text{para todo } n \in \mathbb{N}. 
$$

$\blacksquare$
:::

  e. Sea $X \neq \varnothing$ y $f : X \to X$ aplicación sobreyectiva, supóngase que $f_d^{-1} : X \to X$ es tal que $f \circ f_d^{-1} = I_X$ y $F_{f_d^{-1}} \neq \varnothing$ entonces $F_f \neq \varnothing$.
  
::: {.callout-caution collapse="true"}
### Prueba

Si $F_{f_d^{-1}} \neq \varnothing$, entonces:

$$
\exists \hat{x} \in X : f_d^{-1}(\hat{x}) = \hat{x}
$$

Como $f \circ f_d^{-1} = I_X$, entonces:

$$
f(f_d^{-1}(\hat{x})) = f(\hat{x}) = \hat{x}
\Rightarrow \hat{x} \in F_f \Rightarrow F_f \neq \varnothing 
$$ 

$\blacksquare$
:::

  f. Sea $A$ un conjunto con un número impar de elementos y $f : A \to A$ tal que $f^2(x) = x$ para todo $x \in A$, se tiene entonces que $F_f \neq \varnothing$.
  
::: {.callout-caution collapse="true"}
### Prueba


Se tiene que:

$$
f(f(x)) = x \quad \forall x \in A
$$

Tome $a \in A$.

**Caso 1:** $f(a) = a$  
Entonces $a$ es punto fijo de $f \Rightarrow F_f \neq \varnothing$

**Caso 2:** $f(a) \neq a$  
Entonces:

\begin{align*}
f(f(a)) &= a \Rightarrow f^{-1}(a) = f(a) \Rightarrow f(f(a)) = a \text{ y } f(a) \neq a
\end{align*}

Esto implica que para cada $a \in A$ habrá un $b \in A$ tal que:

$$
f(a) = b \text{ y } f(b) = a
$$

Es decir, $A$ se puede descomponer en pares de elementos $(a,b)$ tales que $f(a) = b$, $f(b) = a$ (biyecciones de orden 2).

Pero esto implicaría que $A$ tiene un número **par** de elementos.

**Sin embargo**, $A$ es impar.  
Por tanto, no todos los elementos pueden emparejarse $\Rightarrow$ al menos uno debe cumplir $f(x) = x$.

$$
\Rightarrow F_f \neq \varnothing 
$$

$\blacksquare$
:::

  g. Sea $f : \mathbb{R} \to \mathbb{R}$ con $f$ continua y acotada entonces $F_f \neq \varnothing$.
  
::: {.callout-caution collapse="true"}
### Prueba

Existe $k \in \mathbb{N}$ tal que $|f(x)| \leq k$ para todo $x \in \mathbb{R}$.

Sea $g(x) := f(x) - x$. Como $f$ es continua y $x \mapsto x$ también lo es, $g$ es continua en $\mathbb{R}$.

Tome $M > k$. Entonces:

- $g(-M) = f(-M) + M \geq -k + M > 0$
- $g(M) = f(M) - M \leq k - M < 0$

Por el teorema del valor intermedio, existe $x^* \in [-M, M]$ tal que $g(x^*) = 0$:

$$
f(x^*) - x^* = 0 \Rightarrow f(x^*) = x^* \Rightarrow x^* \in F_f \Rightarrow F_f \neq \varnothing
$$

$\blacksquare$
:::

  h. Sea $f : \mathbb{R} \to \mathbb{R}$ con $f$ continua y periódica entonces $F_f \neq \varnothing$.
  
::: {.callout-caution collapse="true"}
### Prueba


Sea $f : \mathbb{R} \to \mathbb{R}$ continua y $T > 0$ un periodo, es decir:

$$
f(x + T) = f(x) \quad \forall x \in \mathbb{R}
$$

Sea $g(x) := f(x) - x$, que es continua.

Por la periodicidad:

\begin{align*}
g(x + T) &= f(x + T) - (x + T) = f(x) - x - T = g(x) - T
\end{align*}

Tome $x_0 \in \mathbb{R}$. Entonces:

$$
g(x_0 + kT) = g(x_0) - kT \quad \forall k \in \mathbb{Z}
$$

Tome $m, n \in \mathbb{Z}$ tal que $g(x_0 + mT) > 0$ y $g(x_0 + nT) < 0$.

Entonces, por el teorema del valor intermedio:

$$
\exists x^* \in [x_0 + nT, x_0 + mT] \text{ tal que } g(x^*) = 0 \Rightarrow f(x^*) = x^*
\Rightarrow x^* \in F_f \Rightarrow F_f \neq \varnothing
$$

$\blacksquare$
:::



